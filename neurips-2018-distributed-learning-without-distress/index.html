<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>NeurIPS 2018: Distributed Learning without Distress | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      



	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      
<div style="margin-top:16px; margin-left: auto; margin-right: auto; max-width: 800px;">
    <article class="article" itemscope itemtype="http://schema.org/Article">
      
      <h1 itemprop="name">NeurIPS 2018: Distributed Learning without Distress</h1>
      <div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-12-08 00:00:00 &#43;0000 UTC" itemprop="datePublished">8 December 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/secure-computation">secure computation</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/bargav-jayaraman">Bargav Jayaraman</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>Bargav Jayaraman presented our work on privacy-preserving machine learning at the <a href="https://nips.cc/Conferences/2018/">32<sup>nd</sup> <em>Conference on Neural Information Processing Systems</em></a> (NeurIPS 2018) in Montreal.</p>
<p><em>Distributed learning</em> (sometimes known as <em>federated learning</em>)
allows a group of independent data owners to collaboratively learn a
model over their data sets without exposing their private data.  Our
approach combines <em>differential privacy</em> with secure <em>multi-party
computation</em> to both protect the data during training and produce a
model that provides privacy against inference attacks.</p>
<center>
<iframe width="560" height="315"
	src="https://www.youtube-nocookie.com/embed/rwyWiDyVmjE"
	frameborder="0" allow="accelerometer; autoplay; encrypted-media;
	gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>
<p>We explore two popular methods of differential privacy, output
perturbation and gradient perturbation, and advance the
state-of-the-art for both methods in the distributed learning
setting. In our output perturbation method, the parties combine local
models within a secure computation and then add therequired
differential privacy noise before revealing the model. In our gradient
perturbation method, the data owners collaboratively train a global
model via aniterative learning algorithm. At each iteration, the
parties aggregate their local gradients within a secure computation,
adding sufficient noise to ensure privacy before the gradient updates
are revealed. For both methods, we show that the noise can be reduced
in the multi-party setting by adding the noise inside the
securecomputation after aggregation, asymptotically improving upon the
best previous results. Experiments on real world data sets demonstrate
that our methods providesubstantial utility gains for typical privacy
requirements.</p>
<h2 id="code">Code</h2>
<p><a href="https://github.com/bargavj/distributedMachineLearning"><em><a href="https://github.com/bargavj/distributedMachineLearning">https://github.com/bargavj/distributedMachineLearning</a></em></a></p>
<h2 id="paper">Paper</h2>
<p>Bargav Jayaraman, Lingxiao Wang, David Evans and Quanquan Gu. <a href="//www.cs.virginia.edu/evans/pubs/neurips2018/neurips2018.pdf"><em>Distributed Learning without Distress:
Privacy-Preserving Empirical Risk Minimization</em></a>. <a href="https://nips.cc/Conferences/2018/">32<sup>nd</sup> Conference on Neural Information Processing Systems</a> (NeurIPS). Montreal, Canada. December 2018. (<a href="//www.cs.virginia.edu/evans/pubs/neurips2018/neurips2018.pdf">PDF</a>, 19 pages, including supplemental materials)</p>

      </div>

      <meta itemprop="wordCount" content="254">
      <meta itemprop="datePublished" content="2018-12-08">
      <meta itemprop="url" content="//uvasrg.github.io/neurips-2018-distributed-learning-without-distress/">
    </article>

    <ul class="pagination" role="navigation" aria-label="Pagination" style="margin-top:32px;">
      
      <li class="arrow" aria-disabled="true"><a href="//uvasrg.github.io/can-machine-learning-ever-be-trustworthy/">&laquo; <em>Previous<span class="show-for-sr"> page</span></em>: Can Machine Learning Ever Be Trustworthy?</a></li>
      
      
      <li class="arrow" aria-disabled="true"><a href="//uvasrg.github.io/a-pragmatic-introduction-to-secure-multi-party-computation/"><em>Next<span class="show-for-sr"> page</span></em>: A Pragmatic Introduction to Secure Multi-Party Computation&nbsp;&raquo;</a></li>
      
    </ul>
</div>

    </main>
    
    
<footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>


    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
