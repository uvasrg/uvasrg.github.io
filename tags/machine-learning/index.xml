<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Security Research Group</title>
    <link>//uvasrg.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Security Research Group</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Privacy and Security Research at the University of Virginia</copyright>
    <lastBuildDate>Sun, 04 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="//uvasrg.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Technology: US authorities survey AI ecosystem through antitrust lens</title>
      <link>//uvasrg.github.io/technology-us-authorities-survey-ai-ecosystem-through-antitrust-lens/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/technology-us-authorities-survey-ai-ecosystem-through-antitrust-lens/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m quoted in this article for the International Bar Association:&lt;/p&gt;&#xA;&lt;center&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.ibanet.org/technology-us-authorities-survey-ai-ecosystem-through-antitrust-lens&#34;&gt;&lt;em&gt;Technology: US authorities survey AI ecosystem through antitrust lens&lt;/em&gt;&lt;/a&gt;&lt;br&gt;&#xA;William Roberts, IBA US Correspondent&lt;br&gt;&#xA;Friday 2 August 2024&lt;/p&gt;&#xA;&lt;/center&gt;&#xA;&lt;blockquote&gt;&#xA;Antitrust authorities in the US are targeting the new frontier of artificial intelligence (AI) for potential enforcement action.&#xA;&lt;p&gt;&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;Jonathan Kanter, Assistant Attorney General for the Antitrust Division of the DoJ, warns that the government sees ‘structures and trends in AI that should give us pause’. He says that AI relies on massive amounts of data and computing power, which can give already dominant companies a substantial advantage. ‘Powerful network and feedback effects’ may enable dominant companies to control these new markets, Kanter adds.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Adjectives Can Reveal Gender Biases Within NLP Models</title>
      <link>//uvasrg.github.io/adjectives-can-reveal-gender-biases-within-nlp-models/</link>
      <pubDate>Thu, 17 Aug 2023 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/adjectives-can-reveal-gender-biases-within-nlp-models/</guid>
      <description>&lt;p&gt;Post by &lt;strong&gt;Jason Briegel&lt;/strong&gt; and &lt;a href=&#34;https://hannahxchen.github.io/&#34;&gt;&lt;strong&gt;Hannah Chen&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Because NLP models are trained with human corpora (and now,&#xA;increasingly on text generated by other NLP models that were&#xA;originally trained on human language), they are prone to inheriting&#xA;common human stereotypes and biases. This is problematic, because with&#xA;their growing prominence they may further propagate these stereotypes&#xA;&lt;a href=&#34;https://arxiv.org/abs/1906.08976&#34;&gt;(Sun et al., 2019)&lt;/a&gt;. For example,&#xA;interest is growing in mitigating bias in the field of machine&#xA;translation, where systems such as Google translate were observed to&#xA;default to translating gender-neutral pronouns as male pronouns, even&#xA;with feminine cues &lt;a href=&#34;https://doi.org/10.1162/tacl_a_00401&#34;&gt;(Savoldi et al.,&#xA;2021)&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ISMR 2019: Context-aware Monitoring in Robotic Surgery</title>
      <link>//uvasrg.github.io/ismr-2019-context-aware-monitoring-in-robotic-surgery/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/ismr-2019-context-aware-monitoring-in-robotic-surgery/</guid>
      <description>&lt;p&gt;Samin Yasar presented our paper on &lt;a href=&#34;https://arxiv.org/abs/1901.09802&#34;&gt;&lt;em&gt;Context-award Monitoring in&#xA;Robotic Surgery&lt;/em&gt;&lt;/a&gt; at the 2019&#xA;&lt;a href=&#34;https://web.archive.org/web/20190416013641/http://www.ismr.gatech.edu/&#34;&gt;&lt;em&gt;International Symposium on Medical&#xA;Robotics&lt;/em&gt;&lt;/a&gt;&#xA;(ISMR) in Atlanta, Georgia.&lt;/p&gt;&#xA;&lt;center&gt;&lt;a href=&#34;//uvasrg.github.io/images/surgery.png&#34;&gt;&lt;img src=&#34;//uvasrg.github.io/images/surgery.png&#34; width=&#34;80%&#34;&gt;&lt;/a&gt;&lt;/center&gt;&#xA;&lt;p&gt;Robotic-assisted minimally invasive surgery (MIS) has enabled&#xA;procedures with increased precision and dexterity, but surgical robots&#xA;are still open loop and require surgeons to work with a tele-operation&#xA;console providing only limited visual feedback. In this setting,&#xA;mechanical failures, software faults, or human errors might lead to&#xA;adverse events resulting in patient complications or fatalities. We&#xA;argue that impending adverse events could be detected and mitigated by&#xA;applying context-specific safety constraints on the motions of the&#xA;robot. We present a context-aware safety monitoring system which&#xA;segments a surgical task into subtasks using kinematics data and&#xA;monitors safety constraints specific to each subtask. To test our&#xA;hypothesis about context specificity of safety constraints, we analyze&#xA;recorded demonstrations of dry-lab surgical tasks collected from the&#xA;JIGSAWS database as well as from experiments we conducted on a Raven&#xA;II surgical robot. Analysis of the trajectory data shows that each&#xA;subtask of a given surgical procedure has consistent safety&#xA;constraints across multiple demonstrations by different subjects. Our&#xA;preliminary results show that violations of these safety constraints&#xA;lead to unsafe events, and there is often sufficient time between the&#xA;constraint violation and the safety-critical event to allow for a&#xA;corrective action.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
