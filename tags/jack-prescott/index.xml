<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jack Prescott on Security Research Group</title>
    <link>//uvasrg.github.io/tags/jack-prescott/</link>
    <description>Recent content in Jack Prescott on Security Research Group</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Privacy and Security Research at the University of Virginia</copyright>
    <lastBuildDate>Tue, 28 Sep 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="//uvasrg.github.io/tags/jack-prescott/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>UVA News Article</title>
      <link>//uvasrg.github.io/uva-news-article/</link>
      <pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/uva-news-article/</guid>
      <description>&lt;p&gt;UVA News has an article by Audra Book on our research on security and&#xA;privacy of machine learning (with some very nice quotes from several&#xA;students in the group, and me saying something positive about the&#xA;NSA!): &lt;a href=&#34;https://engineering.virginia.edu/news/2021/09/computer-science-professor-david-evans-and-his-team-conduct-experiments-understand&#34;&gt;&lt;em&gt;Computer science professor David Evans and his team conduct&#xA;experiments to understand security and privacy risks associated with&#xA;machine&#xA;learning&lt;/em&gt;&lt;/a&gt;,&#xA;8 September 2021.&lt;/p&gt;&#xA;&lt;div class=&#34;articletext&#34;&gt;&#xA;&lt;p&gt;David Evans, professor of computer science in the University of Virginia School of Engineering and Applied Science, is leading research to understand how machine learning models can be compromised.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Improved Estimation of Concentration (ICLR 2021)</title>
      <link>//uvasrg.github.io/improved-estimation-of-concentration-iclr-2021/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/improved-estimation-of-concentration-iclr-2021/</guid>
      <description>&lt;p&gt;Our paper on &lt;a href=&#34;https://openreview.net/forum?id=BUlyHkzjgmA&#34;&gt;&lt;em&gt;Improved Estimation of Concentration Under ℓ&lt;sub&gt;p&lt;/sub&gt;-Norm Distance Metrics Using Half Spaces&lt;/em&gt;&lt;/a&gt; (Jack Prescott, &lt;a href=&#34;https://people.virginia.edu/~xz7bc/&#34;&gt;Xiao Zhang&lt;/a&gt;, and David Evans) will be presented at ICLR 2021.&lt;/p&gt;&#xA;&lt;p&gt;&lt;b&gt;Abstract:&lt;/b&gt; Concentration of measure has been argued to be the&#xA;fundamental cause of adversarial vulnerability. Mahloujifar et&#xA;al. (2019) presented an empirical way to measure the concentration of&#xA;a data distribution using samples, and employed it to find lower&#xA;bounds on intrinsic robustness for several benchmark&#xA;datasets. However, it remains unclear whether these lower bounds are&#xA;tight enough to provide a useful approximation for the intrinsic&#xA;robustness of a dataset. To gain a deeper understanding of the&#xA;concentration of measure phenomenon, we first extend the Gaussian&#xA;Isoperimetric Inequality to non-spherical Gaussian measures and&#xA;arbitrary ℓ&lt;sub&gt;p&lt;/sub&gt;-norms (&lt;em&gt;p&lt;/em&gt; ≥ 2). We leverage these&#xA;theoretical insights to design a method that uses half-spaces to&#xA;estimate the concentration of any empirical dataset under&#xA;ℓ&lt;sub&gt;p&lt;/sub&gt;-norm distance metrics. Our proposed algorithm is more&#xA;efficient than Mahloujifar et al. (2019)&amp;rsquo;s, and experiments on&#xA;synthetic datasets and image benchmarks demonstrate that it is able to&#xA;find much tighter intrinsic robustness bounds. These tighter estimates&#xA;provide further evidence that rules out intrinsic dataset&#xA;concentration as a possible explanation for the adversarial&#xA;vulnerability of state-of-the-art classifiers.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
