<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Fnu Suya on Security Research Group</title>
    <link>//uvasrg.github.io/tags/fnu-suya/</link>
    <description>Recent content in Fnu Suya on Security Research Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Privacy and Security Research at the University of Virginia</copyright>
    <lastBuildDate>Thu, 13 Aug 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="//uvasrg.github.io/tags/fnu-suya/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Hybrid Batch Attacks at USENIX Security 2020</title>
      <link>//uvasrg.github.io/hybrid-batch-attacks-at-usenix-security-2020/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>//uvasrg.github.io/hybrid-batch-attacks-at-usenix-security-2020/</guid>
      <description>Here&amp;rsquo;s the video for Fnu Suya&amp;rsquo;s presentation on Hybrid Batch Attacks at USENIX Security 2020:
 
Download Video [mp4]
 Blog Post
Paper: [PDF] [arXiv]</description>
    </item>
    
    <item>
      <title>USENIX Security 2020: Hybrid Batch Attacks</title>
      <link>//uvasrg.github.io/usenix-security-2020-hybrid-batch-attacks/</link>
      <pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>//uvasrg.github.io/usenix-security-2020-hybrid-batch-attacks/</guid>
      <description>New: Video Presentation
Finding Black-box Adversarial Examples with Limited Queries Black-box attacks generate adversarial examples (AEs) against deep neural networks with only API access to the victim model.
Existing black-box attacks can be grouped into two main categories:
  Transfer Attacks use white-box attacks on local models to find candidate adversarial examples that transfer to the target model.
  Optimization Attacks use queries to the target model and apply optimization techniques to search for adversarial examples.</description>
    </item>
    
    <item>
      <title>Research Symposium Posters</title>
      <link>//uvasrg.github.io/research-symposium-posters/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>//uvasrg.github.io/research-symposium-posters/</guid>
      <description>Five students from our group presented posters at the department&amp;rsquo;s Fall Research Symposium:
 
Anshuman Suri&#39;s Overview Talk   Bargav Jayaraman, Evaluating Differentially Private Machine Learning In Practice [Poster]
[Paper (USENIX Security 2019)]  

 Hannah Chen [Poster]  

 Xiao Zhang [Poster]
[Paper (NeurIPS 2019)]  

 Mainudding Jonas [Poster]  

 Fnu Suya [Poster]
[Paper (USENIX Security 2020)]  </description>
    </item>
    
    <item>
      <title>Wahoos at Oakland</title>
      <link>//uvasrg.github.io/wahoos-at-oakland/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>//uvasrg.github.io/wahoos-at-oakland/</guid>
      <description>UVA Group Dinner at IEEE Security and Privacy 2018 Including our newest faculty member, Yongwhi Kwon, joining UVA in Fall 2018!


Yuan Tian, Fnu Suya, Mainuddin Jonas, Yongwhi Kwon, David Evans, Weihang Wang, Aihua&amp;nbsp;Chen,&amp;nbsp;Weilin&amp;nbsp;Xu
  ## Poster Session 
Fnu Suya (with Yuan Tian and David Evans), Adversaries Don’t Care About Averages: Batch Attacks on Black-Box Classifiers [PDF]  
Mainuddin Jonas (with David Evans), Enhancing Adversarial Example Defenses Using Internal Layers [PDF]         </description>
    </item>
    
  </channel>
</rss>