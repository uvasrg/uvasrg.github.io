+++
date = "27 Apr 2025"
draft = false
title = "Steering the CensorShip"
categories = ["research"]
tags = ["Hannah Cyberey", "David Evans", "censorship", "large language models", "steering", "alignment"]
+++

<center>
<a href="https://hannahxchen.github.io/blog/2025/censorship-steering/"><img src="/images/steeringexamples.png" width="80%" alt="Steering Censorship Examples"></a>

_Orthodoxy means not thinking‚Äînot needing to think._  
(George Orwell, 1984)

</center>

###
**Uncovering Representation Vectors for LLM 'Thought' Control**

Hannah Cyberey's [**blog post**](https://hannahxchen.github.io/blog/2025/censorship-steering/) summarizes our work on controlling the censorship imposed through refusal and thought suppression in model outputs. 

**Paper:** Hannah Cyberey and David Evans. [_Steering the CensorShip: Uncovering Representation Vectors for LLM ‚ÄúThought‚Äù Control_](https://arxiv.org/abs/2504.17130). 23 April 2025.

**Demos:** 
- üê≥ <a href="https://mightbeevil.com/censorship">Steeing Thought Suppression</a>  with DeepSeek-R1-Distill-Qwen-7B (this demo should work for everyone!)

- ü¶ô <a href="https://hannahcyberey-refusal-censorship-steering.hf.space/">Steering Refusal&ndash;Compliance</a> with Llama-3.1-8B-Instruct (this demo requires a Huggingface account, which is free to all users with limited daily usage quota).

**Code:** https://github.com/hannahxchen/llm-censorship-steering

