<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>ICLR 2022: Understanding Intrinsic Robustness Using Label Uncertainty | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      



	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      
<div style="margin-top:16px; margin-left: auto; margin-right: auto; max-width: 800px;">
    <article class="article" itemscope itemtype="http://schema.org/Article">
      
      <h1 itemprop="name">ICLR 2022: Understanding Intrinsic Robustness Using Label Uncertainty</h1>
      <div class="post-metadata">
  <span class="post-date">
    <time datetime="2022-03-24 00:00:00 &#43;0000 UTC" itemprop="datePublished">24 March 2022</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/xiao-zhang">Xiao Zhang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/iclr">ICLR</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/intrinsic-robustness">intrinsic robustness</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>(Blog post written by <a href="https://xiao-zhang.net/">Xiao Zhang</a>)</p>
<p>Motivated by the empirical hardness of developing robust classifiers
against adversarial perturbations, researchers began asking the
question “<em>Does there even exist a robust classifier?</em>”. This is
formulated as the <strong><em>intrinsic robustness problem</em></strong> <a href="https://proceedings.neurips.cc/paper/2019/file/46f76a4bda9a9579eab38a8f6eabcda1-Paper.pdf">(Mahloujifar et
al.,
2019)</a>,
where the goal is to characterize the maximum adversarial robustness
possible for a given robust classification problem. Building upon the
connection between adversarial robustness and classifier’s error
region, it has been shown that if we restrict the search to the set of
imperfect classifiers, the intrinsic robustness problem can be reduced
to the <strong><em>concentration of measure problem</em></strong>.</p>
<p>
<center><img src="/images/figs/concentration.png" width=50% alt="Concentration of Measure"></center>
</p>
<p>In this work, we argue that the standard concentration of measure
problem is not sufficient to capture a realistic intrinsic robustness
limit for a classification problem. In particular, the standard
concentration function is defined as an inherent property regarding
the input metric probability space, which does not take account of the
underlying label information. However, such label information is
essential for any supervised learning problem, including adversarially
robust classification, so must be incorporated into intrinsic
robustness limits. By introducing a novel definition of <strong><em>label
uncertainty</em></strong>, which characterizes the average uncertainty of label
assignments for an input region, we empirically demonstrate that error
regions induced by state-of-the-art models tend to have much higher
label uncertainty than randomly-selected subsets.</p>
<p>
<center><img src="/images/figs/err_reg_lu.png" width=50% alt="Error Regions have higher label uncertainty"></center>
</p>
<p>This observation motivates us to adapt a concentration estimation
algorithm to account for label uncertainty, where we focus on
understanding the concentration of measure phenomenon with respect to
input regions with label uncertainty exceeding a certain threshold
$\gamma&gt;0$. The intrinsic robustness estimates we obtain by
incorporating label uncertainty (shown as the green dots in the figure
below) are much lower than prior limits, suggesting that compared with
the concentration of measure phenomenon, the <strong><em>existence of uncertain
inputs</em></strong> may explain more fundamentally the adversarial vulnerability
of state-of-the-art robustly-trained models.</p>
<p>
<center><img src="/images/figs/result.png" width=50% alt="Intrinsic robustness with label uncertainty"></center>
</p>
<p><b>Paper:</b> <a href="https://xiao-zhang.net">Xiao Zhang</a> and <a href="https://www.cs.virginia.edu/evans/">David Evans</a>. <strong><em>Understanding Intrinsic Robustness Using Label Uncertainty</em></strong>. <em>In <a href="https://iclr.cc/Conferences/2022">Tenth International Conference on Learning Representations</a> (ICLR), April 2022.</em> [<a href="https://openreview.net/pdf?id=6ET9SzlgNX">PDF</a>]  [<a href="https://openreview.net/forum?id=6ET9SzlgNX">OpenReview</a>] [<a href="https://arxiv.org/abs/2107.03250">ArXiv</a>]</p>
<p><b>Code:</b> <a href="https://github.com/xiaozhanguva/intrinsic_rob_lu"><em>https://github.com/xiaozhanguva/intrinsic_rob_lu</em></a></p>
<center>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/YrxO1zM1KuM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

      </div>

      <meta itemprop="wordCount" content="331">
      <meta itemprop="datePublished" content="2022-03-24">
      <meta itemprop="url" content="//uvasrg.github.io/iclr-2022-understanding-intrinsic-robustness-using-label-uncertainty/">
    </article>

    <ul class="pagination" role="navigation" aria-label="Pagination" style="margin-top:32px;">
      
      <li class="arrow" aria-disabled="true"><a href="//uvasrg.github.io/microsoft-research-summit-surprising-and-unsurprising-inference-risks-in-machine-learning/">&laquo; <em>Previous<span class="show-for-sr"> page</span></em>: Microsoft Research Summit: Surprising (and unsurprising) Inference Risks in Machine Learning</a></li>
      
      
      <li class="arrow" aria-disabled="true"><a href="//uvasrg.github.io/congratulations-dr.-zhang/"><em>Next<span class="show-for-sr"> page</span></em>: Congratulations, Dr. Zhang!&nbsp;&raquo;</a></li>
      
    </ul>
</div>

    </main>
    
    
<footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>


    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
