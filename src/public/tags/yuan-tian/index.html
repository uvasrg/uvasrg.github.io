<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>Yuan Tian | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      
        <p class="groupstyle">Security and Privacy Research</br>at the University of Virginia</p>
	      
	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      
<div style="margin-top:16px; margin-left: auto; margin-right: auto; max-width: 800px;">
<div class="row">
  <div class="column small-12">
    
    
    <h2><a href="/satml-talk-sok-pitfalls-in-evaluating-black-box-attacks/">SaTML Talk: SoK: Pitfalls in Evaluating Black-Box Attacks</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2024-04-22 00:00:00 &#43;0000 UTC" itemprop="datePublished">22 April 2024</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/anshuman-suri">Anshuman Suri</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/tingwei-zhang">Tingwei Zhang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jingtao-hong">Jingtao Hong</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/david-evans">David Evans</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/satml">SaTML</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/black-box-adversarial-attacks">black-box adversarial attacks</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/systemization-of-knowledge">systemization of knowledge</a>
    
  </span>
  
  
</div>


<p><a href="https://www.anshumansuri.com/">Anshuman Suri</a>&rsquo;s talk at <a href="https://satml.org/">IEEE Conference on Secure and Trustworthy Machine Learning</a> (SaTML) is now available:</p>
<center>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ui4HMGe3aUs?si=M2A-uD77s4BdhXPR" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</center>
<p>See the <a href="https://uvasrg.github.io/sok-pitfalls-in-evaluating-black-box-attacks/">earlier blog post</a> for more on the work, and the paper at <a href="https://arxiv.org/abs/2310.17534">https://arxiv.org/abs/2310.17534</a>.</p>

	

    
    <h2><a href="/sok-pitfalls-in-evaluating-black-box-attacks/">SoK: Pitfalls in Evaluating Black-Box Attacks</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2023-12-20 00:00:00 &#43;0000 UTC" itemprop="datePublished">20 December 2023</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/anshuman-suri">Anshuman Suri</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/tingwei-zhang">Tingwei Zhang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jingtao-hong">Jingtao Hong</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/david-evans">David Evans</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/satml">SaTML</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/black-box-adversarial-attacks">black-box adversarial attacks</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/systemization-of-knowledge">systemization of knowledge</a>
    
  </span>
  
  
</div>


<p>Post by <strong><a href="https://www.anshumansuri.com/">Anshuman Suri</a></strong> and <strong><a href="https://fsuya.org/">Fnu Suya</a></strong></p>
<p>Much research has studied black-box attacks on image classifiers,
where adversaries generate adversarial examples against unknown target
models without having access to their internal information. Our
analysis of over 164 attacks (published in 102 major security, machine
learning and security conferences) shows how these works make
different assumptions about the adversary’s knowledge.</p>
<p>The current literature lacks cohesive organization centered around the
threat model. Our <a href="https://arxiv.org/abs/2310.17534">SoK paper</a> (to
appear at <a href="https://satml.org/">IEEE SaTML 2024</a>) introduces a taxonomy
for systematizing these attacks and demonstrates the importance of
careful evaluations that consider adversary resources and threat
models.</p>
<p class="text-right"><a href="/sok-pitfalls-in-evaluating-black-box-attacks/">Read More…</a></p>
	

    
    <h2><a href="/model-targeted-poisoning-attacks-with-provable-convergence/">Model-Targeted Poisoning Attacks with Provable Convergence</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2021-06-29 00:00:00 &#43;0000 UTC" itemprop="datePublished">29 June 2021</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/model-targeted-poisoning-attacks">model-targeted poisoning attacks</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/saeed-mahloujifar">Saeed Mahloujifar</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/anshuman-suri">Anshuman Suri</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/david-evans">David Evans</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/icml-2021">ICML 2021</a>
    
  </span>
  
  
</div>


<p>(Post by Sean Miller, using images adapted from Suya&rsquo;s talk slides)</p>
<h2 id="data-poisoning-attacks">Data Poisoning Attacks</h2>
<p>Machine learning models are often trained using data from untrusted
sources, leaving them open to poisoning attacks where adversaries use
their control over a small fraction of that training data to poison
the model in a particular way.</p>
<p>Most work on poisoning attacks is directly driven by an attacker&rsquo;s
objective, where the adversary chooses poisoning points that maximize
some target objective. Our work focuses on <em>model-targeted</em> poisoning
attacks, where the adversary splits the attack into choosing a target
model that satisfies the objective and then choosing poisoning points
that induce the target model.</p>
<p class="text-right"><a href="/model-targeted-poisoning-attacks-with-provable-convergence/">Read More…</a></p>
	

    
    <h2><a href="/hybrid-batch-attacks-at-usenix-security-2020/">Hybrid Batch Attacks at USENIX Security 2020</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-08-13 00:00:00 &#43;0000 UTC" itemprop="datePublished">13 August 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jianfeng-chi">Jianfeng Chi</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/usenix-security">USENIX Security</a>
    
  </span>
  
  
</div>


<p>Here&rsquo;s the video for Suya&rsquo;s presentation on <a href="/usenix-security-2020-hybrid-batch-attacks">Hybrid Batch Attacks</a> at USENIX Security 2020:</p>
<center>
  <video width="90%" id="usenix-media-video-1" data-setup="{}" poster="" class="video-js vjs-default-skin vjs-big-play-centered" preload="auto" controls>
    <source src='https://2459d6dc103cb5933875-c0245c5c937c5dedcca3f1764ecc9b2f.ssl.cf2.rackcdn.com/sec20/videos/0813/s5_machine_learning_1/3_sec20summer-paper412-presentation-video.mp4' type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'>
  </video><br> 
<a href="https://2459d6dc103cb5933875-c0245c5c937c5dedcca3f1764ecc9b2f.ssl.cf2.rackcdn.com/sec20/videos/0813/s5_machine_learning_1/3_sec20summer-paper412-presentation-video.mp4">Download Video [mp4]</a></p>
</center>
<p><a href="/usenix-security-2020-hybrid-batch-attacks">Blog Post</a><br>
Paper: [<a href="/docs/hybrid_attack.pdf">PDF</a>] [<a href="https://arxiv.org/abs/1908.07000">arXiv</a>]</p>

	

    
    <h2><a href="/usenix-security-2020-hybrid-batch-attacks/">USENIX Security 2020: Hybrid Batch Attacks</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-12-14 00:00:00 &#43;0000 UTC" itemprop="datePublished">14 December 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jianfeng-chi">Jianfeng Chi</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/usenix-security">USENIX Security</a>
    
  </span>
  
  
</div>


<p><b><font color="red">New:</font> <a href="/hybrid-batch-attacks-at-usenix-security-2020/">Video Presentation</a></b></p>
<h2 id="finding-black-box-adversarial-examples-with-limited-queries">Finding Black-box Adversarial Examples with Limited Queries</h2>
<p>Black-box attacks generate adversarial examples (AEs) against deep
neural networks with only API access to the victim model.</p>
<p>Existing black-box attacks can be grouped into two main categories:</p>
<ul>
<li>
<p><strong>Transfer Attacks</strong> use white-box attacks on local models to find
candidate adversarial examples that transfer to the target model.</p>
</li>
<li>
<p><strong>Optimization Attacks</strong> use queries to the target model and apply
optimization techniques to search for adversarial examples.</p>
<p class="text-right"><a href="/usenix-security-2020-hybrid-batch-attacks/">Read More…</a></p>
	

    
    <h2><a href="/wahoos-at-oakland/">Wahoos at Oakland</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-05-29 00:00:00 &#43;0000 UTC" itemprop="datePublished">29 May 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/alumni">alumni</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/pictures">pictures</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/posters">posters</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/mainuddin-jonas">Mainuddin Jonas</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yongwhi-kwon">Yongwhi Kwon</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/weilin-xu">Weilin Xu</a>
    
  </span>
  
  
</div>


<h2 id="uva-group-dinner-at-ieee-security-and-privacy-2018">UVA Group Dinner at IEEE Security and Privacy 2018</h2>
<p>Including our newest faculty member, <a href="https://www.cs.purdue.edu/homes/kwon58/#summary">Yongwhi Kwon</a>, joining UVA in Fall 2018!<br /></p>
<center><br />
<a href="/images/srg2018/ORG_DSC07202.jpg"><img src="/images/srg2018/ORG_DSC07202.jpg" width="680"></a><br />
<small>Yuan Tian, Fnu Suya, Mainuddin Jonas, Yongwhi Kwon, David Evans, Weihang Wang, Aihua&nbsp;Chen,&nbsp;Weilin&nbsp;Xu</small><br />
</center>
</p>
<p>
## Poster Session
<table width="100%">
<tr valign="top">
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180521_193906.jpg"><img src="/images/srg2018/IMG_20180521_193906-3.jpg" height="360"></a><br />
Fnu Suya (with Yuan Tian and David Evans), <em>Adversaries Don’t Care About Averages: Batch Attacks on Black-Box Classifiers</em> <a href="https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper37-poster-abstract.pdf">[PDF]</a>
</td>
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180521_193914.jpg"><img src="/images/srg2018/IMG_20180521_193914-2.jpg" height="360"></a><br />
Mainuddin Jonas (with David Evans), <em>Enhancing Adversarial Example Defenses Using Internal Layers</em> <a href="https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper29-poster-abstract.pdf">[PDF]</a>
</td>
</tr>
<tr valign="top">
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180522_153017.jpg"><img src="/images/srg2018/IMG_20180522_153017-2.jpg" height="300"></a>
</td>
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180522_153109.jpg"><img src="/images/srg2018/IMG_20180522_153109-2.jpg" height="300"></a>
</td>
</tr>
</table>

	

    
    <div class="row">
  <div class="column small-12">
    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li><span>Page 1 of 1</span></li>      
      
    </ul>    
    All Posts by <a href="//uvasrg.github.io/categories">Category</a> or <a href="//uvasrg.github.io/tags">Tags</a>.

  </div>
</div>

  </div>
</div>
</div>

    </main>
    
    
    <footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>

    
    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
