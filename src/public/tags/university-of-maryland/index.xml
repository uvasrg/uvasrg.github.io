<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>University of Maryland on Security Research Group</title>
    <link>//uvasrg.github.io/tags/university-of-maryland/</link>
    <description>Recent content in University of Maryland on Security Research Group</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Privacy and Security Research at the University of Virginia</copyright>
    <lastBuildDate>Fri, 07 Dec 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="//uvasrg.github.io/tags/university-of-maryland/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Can Machine Learning Ever Be Trustworthy?</title>
      <link>//uvasrg.github.io/can-machine-learning-ever-be-trustworthy/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/can-machine-learning-ever-be-trustworthy/</guid>
      <description>&lt;p&gt;I gave the &lt;a href=&#34;https://ece.umd.edu/events/distinguished-colloquium-series&#34;&gt;&lt;em&gt;Booz Allen Hamilton Distinguished Colloquium&lt;/em&gt;&lt;/a&gt; at the&#xA;University of Maryland on &lt;em&gt;Can Machine Learning Ever Be Trustworthy?&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;center&gt;&#xA;[Video](https://vid.umd.edu/detsmediasite/Play/e8009558850944bfb2cac477f8d741711d?catalog=74740199-303c-49a2-9025-2dee0a195650) &amp;middot;&#xA;[SpeakerDeck](https://speakerdeck.com/evansuva/can-machine-learning-ever-be-trustworthy)&#xA;&lt;p&gt;&lt;a href=&#34;//uvasrg.github.io/images/umd2018/umd.jpg&#34;&gt;&lt;img src=&#34;//uvasrg.github.io/images/umd2018/umd.jpg&#34; width=&#34;80%&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/center&gt;&#xA;   &lt;div class=&#34;abstract&#34;&gt;&#xA;&lt;center&gt;&lt;b&gt;Abstract&lt;/b&gt;&lt;/center&gt;&#xA;Machine learning has produced extraordinary results over the past few years, and machine learning systems are rapidly being deployed for&#xA;critical tasks, even in adversarial environments.  This talk will survey some of the reasons building trustworthy machine learning&#xA;systems is inherently impossible, and dive into some recent research on adversarial examples. Adversarial examples are inputs crafted&#xA;deliberately to fool a machine learning system, often by making small, but targeted perturbations, starting from a natural seed example. Over the past few years, there has been an explosion of research in adversarial examples but we are only beginning to understand their&#xA;mysteries and just taking the first steps towards principled and effective defenses. The general problem of adversarial examples, however, has been at the core of information security for thousands of years. In this talk, I&#39;ll look at some of the long-forgotten lessons&#xA;from that quest, unravel the huge gulf between theory and practice in adversarial machine learning, and speculate on paths toward&#xA;trustworthy machine learning systems.&#xA;   &lt;/div&gt;</description>
    </item>
  </channel>
</rss>
