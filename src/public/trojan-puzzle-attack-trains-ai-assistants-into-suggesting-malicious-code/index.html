<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>Trojan Puzzle attack trains AI assistants into suggesting malicious code | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      



	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      
<div style="margin-top:16px; margin-left: auto; margin-right: auto; max-width: 800px;">
    <article class="article" itemscope itemtype="http://schema.org/Article">
      
      <h1 itemprop="name">Trojan Puzzle attack trains AI assistants into suggesting malicious code</h1>
      <div class="post-metadata">
  <span class="post-date">
    <time datetime="2023-01-10 00:00:00 &#43;0000 UTC" itemprop="datePublished">10 January 2023</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/large-language-models">large language models</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/copilot">copilot</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/poisoning">poisoning</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>Bleeping Computer has a <a href="https://www.bleepingcomputer.com/news/security/trojan-puzzle-attack-trains-ai-assistants-into-suggesting-malicious-code/">story on our work</a> (in collaboration with Microsoft Research) on poisoning code suggestion models:</p>
<h1>Trojan Puzzle attack trains AI assistants into suggesting malicious code</h1>
<p>By <b>Bill Toulas</b></p>
<center>
<img alt="Person made of jigsaw puzzle pieces" height="900" src="https://www.bleepstatic.com/content/hl-images/2022/10/09/mystery-hacker.jpg" width="80%"></img>
</center>
<p> </p>
<p>Researchers at the universities of California, Virginia, and Microsoft have devised a new poisoning attack that could trick AI-based coding assistants into suggesting dangerous code.</p>
<p>Named &lsquo;Trojan Puzzle,&rsquo; the attack stands out for bypassing static detection and signature-based dataset cleansing models, resulting in the AI models being trained to learn how to reproduce dangerous payloads.</p>
<p>Given the rise of coding assistants like <a href="https://www.bleepingcomputer.com/news/security/microsoft-sued-for-open-source-piracy-through-github-copilot/" target="_blank">GitHub&rsquo;s Copilot</a> and <a href="https://www.bleepingcomputer.com/news/technology/openais-new-chatgpt-bot-10-coolest-things-you-can-do-with-it/" target="_blank">OpenAI&rsquo;s ChatGPT</a>, finding a covert way to stealthily plant malicious code in the training set of AI models could have widespread consequences, potentially leading to large-scale supply-chain attacks.</p>
<h2>Poisoning AI datasets</h2>
<p>AI coding assistant platforms are trained using public code repositories found on the Internet, including the immense amount of code on GitHub.</p>
<p>Previous studies have <a href="https://www.usenix.org/system/files/sec21-schuster.pdf" target="_blank" rel="nofollow noopener">already explored</a> the idea of poisoning a training dataset of AI models by purposely introducing malicious code in public repositories in the hopes that it will be selected as training data for an AI coding assistant.</p>
<p>However, the researchers of the new study state that the previous methods can be more easily detected using static analysis tools.</p>
<p>&ldquo;While Schuster et al.&rsquo;s study presents insightful results and shows that poisoning attacks are a threat against automated code-attribute suggestion systems, it comes with an important limitation,&rdquo; explains the researchers in the new &ldquo;<a href="http://arxiv.org/pdf/2301.02344.pdf" target="_blank" rel="nofollow noopener">TROJANPUZZLE: Covertly Poisoning Code-Suggestion Models</a>&rdquo; paper.</p>
<p>&ldquo;Specifically, Schuster et al.&rsquo;s poisoning attack explicitly injects the insecure payload into the training data.&rdquo;</p>
<p>&ldquo;This means the poisoning data is detectable by static analysis tools that can remove such malicious inputs from the training set,&rsquo; continues the report.</p></p>
<p>The second, more covert method involves hiding the payload onto docstrings instead of including it directly in the code and using a &ldquo;trigger&rdquo; phrase or word to activate it.</p>
<p>&hellip;</p>
<p><a href="https://www.bleepingcomputer.com/news/security/trojan-puzzle-attack-trains-ai-assistants-into-suggesting-malicious-code/">Full Article</a></p>

      </div>

      <meta itemprop="wordCount" content="319">
      <meta itemprop="datePublished" content="2023-01-10">
      <meta itemprop="url" content="//uvasrg.github.io/trojan-puzzle-attack-trains-ai-assistants-into-suggesting-malicious-code/">
    </article>

    <ul class="pagination" role="navigation" aria-label="Pagination" style="margin-top:32px;">
      
      <li class="arrow" aria-disabled="true"><a href="//uvasrg.github.io/dissecting-distribution-inference/">&laquo; <em>Previous<span class="show-for-sr"> page</span></em>: Dissecting Distribution Inference</a></li>
      
      
      <li class="arrow" aria-disabled="true"><a href="//uvasrg.github.io/uh-oh-theres-a-new-way-to-poison-code-models/"><em>Next<span class="show-for-sr"> page</span></em>: Uh-oh, there&#39;s a new way to poison code models&nbsp;&raquo;</a></li>
      
    </ul>
</div>

    </main>
    
    
<footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>


    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
