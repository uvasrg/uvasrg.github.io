<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>Posts | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      
        <p class="groupstyle">Security and Privacy Research</br>at the University of Virginia</p>
	      
	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      

<div class="container">
<div class="content">
<div class="row">
    
    
    <h2><a href="/mutually-assured-destruction-and-the-impending-ai-apocalypse/">Mutually Assured Destruction and the Impending AI Apocalypse</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-08-13 00:00:00 &#43;0000 UTC" itemprop="datePublished">13 August 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/woot">WOOT</a>
    
  </span>
  
  
</div>


<p>I gave a keynote talk at <a href="https://www.usenix.org/conference/woot18/workshop-program">USENIX Workshop of Offensive Technologies</a>, Baltimore, Maryland, 13 August 2018. </p></p>
<p>The title and abstract are what I provided for the WOOT program, but unfortunately (or maybe fortunately for humanity!) I wasn&#8217;t able to actually figure out a talk to match the title and abstract I provided.</p>
<blockquote><p>
The history of security includes a long series of arms races, where a new technology emerges and is subsequently developed and exploited by both defenders and attackers. Over the past few years, &#8220;Artificial Intelligence&#8221; has re-emerged as a potentially transformative technology, and deep learning in particular has produced a barrage of amazing results. We are in the very early stages of understanding the potential of this technology in security, but more worryingly, seeing how it may be exploited by malicious individuals and powerful organizations. In this talk, I&#8217;ll look at what lessons might be learned from previous security arms races, consider how asymmetries in AI may be exploited by attackers and defenders, touch on some recent work in adversarial machine learning, and hopefully help progress-loving Luddites figure out how to survive in a world overrun by AI doppelgängers, GAN gangs, and gibbon-impersonating pandas.
</p>
<p class="text-right"><a href="/mutually-assured-destruction-and-the-impending-ai-apocalypse/">Read More…</a></p>
	

    
    <h2><a href="/cybersecurity-summer-camp/">Cybersecurity Summer Camp</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-07-07 00:00:00 &#43;0000 UTC" itemprop="datePublished">7 July 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/education">education</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/ahmed-ibrahim">Ahmed Ibrahim</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/summer-camp">summer camp</a>
    
  </span>
  
  
</div>


<p>I helped organize a <a href="https://www.ahmed.ai/cyberwars2018">summer camp for high school teachers focused on cybersecurity</a>, led by Ahmed Ibrahim.  Some of the materials from the camp on cryptography, including the Jefferson Wheel and visual cryptography are here: <a href="https://github.com/evansuva/cipherschool"><em>Cipher School for Muggles</em></a>.</p>
</p>
<p>
<center><br />
<img src="https://web.archive.org/web/20180707220753im_/https://news.virginia.edu/sites/default/files/cyber_security_class_da_inline_01.jpg" width="90%"></img><br />
</center><br />
<a href="https://news.virginia.edu/content/cybersecurity-goes-summer-camp"><em>Cybersecurity Goes to Summer Camp</em></a>. UVA Today. 22 July 2018. [<a href="https://web.archive.org/web/20180707220753/https://news.virginia.edu/content/cybersecurity-goes-summer-camp">archive.org</a>]</p>
<blockquote><p>
Earlier this week, 25 high school teachers – including 21 from Virginia – filled a glass-walled room in Rice Hall, sitting in high adjustable chairs at wheeled work tables, their laptops open, following a lecture with graphics about the dangers that lurk in cyberspace and trying to figure out how to pass the information on to a generation that seems to share the most intimate details of life online. &#8220;I think understanding privacy is important to that generation that uses Facebook and Snapchat,&#8221; said David Evans, a computer science professor who helped organize the camp. &#8220;We hope to give teachers some ideas and tools to get their students excited about learning about cryptography, privacy and cybersecurity, and how these things can impact them.&#8221;
</p>
<p class="text-right"><a href="/cybersecurity-summer-camp/">Read More…</a></p>
	

    
    <h2><a href="/dependable-and-secure-machine-learning/">Dependable and Secure Machine Learning</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-07-07 00:00:00 &#43;0000 UTC" itemprop="datePublished">7 July 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/dependable-machine-learning">dependable machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/homa-alemzadeh">Homa Alemzadeh</a>
    
  </span>
  
  
</div>


<p>I co-organized, with <a
href="http://faculty.virginia.edu/alemzadeh/">Homa Alemzadeh</a> and
<a href="http://blogs.ubc.ca/karthik/">Karthik Pattabiraman</a>, a
workshop on trustworthy machine learning attached to DSN 2018, in
Luxembourg: <a href="https://dependablesecureml.github.io/">DSML:
Dependable and Secure Machine Learning</a>.</p></p>
<center>
<img src="/images/dsn2018.jpg" width="80%">
</center>
	

    
    <h2><a href="/dls-keynote-is-adversarial-examples-an-adversarial-example/">DLS Keynote: Is &#39;adversarial examples&#39; an Adversarial Example?</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-05-29 00:00:00 &#43;0000 UTC" itemprop="datePublished">29 May 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/talks">talks</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/videos">videos</a>
    
  </span>
  
  
</div>


<p>I gave a keynote talk at the <a href="https://www.ieee-security.org/TC/SPW2018/DLS/#"><em>1st Deep Learning and Security Workshop</em></a> (co-located with the 39th <em>IEEE Symposium on Security and Privacy</em>). San Francisco, California. 24 May 2018</p></p>
<p><center><br />
<iframe width="640" height="360" src="https://www.youtube-nocookie.com/embed/sFhD6ABghf8?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</p>
<p>
<script async class="speakerdeck-embed"
	data-id="9d2c5bf9b3444a8a992762f5cd6ea7fe"
	data-ratio="1.77777777777778" src="http://speakerdeck.com/assets/embed.js"></script><br />
</center>
</p>
<p>
<center><br />
<b>Abstract</b><br />
</center></p>
<p>
Over the past few years, there has been an explosion of research in security of machine learning and on adversarial examples in particular. Although this is in many ways a new and immature research area, the general problem of adversarial examples has been a core problem in information security for thousands of years. In this talk, I&#8217;ll look at some of the long-forgotten lessons from that quest and attempt to understand what, if anything, has changed now we are in the era of deep learning classifiers. I will survey the prevailing definitions for &#8220;adversarial examples&#8221;, argue that those definitions are unlikely to be the right ones, and raise questions about whether those definitions are leading us astray.</p>
<p class="text-right"><a href="/dls-keynote-is-adversarial-examples-an-adversarial-example/">Read More…</a></p>
	

    
    <h2><a href="/wahoos-at-oakland/">Wahoos at Oakland</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-05-29 00:00:00 &#43;0000 UTC" itemprop="datePublished">29 May 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/alumni">alumni</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/pictures">pictures</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/posters">posters</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/mainuddin-jonas">Mainuddin Jonas</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yongwhi-kwon">Yongwhi Kwon</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/weilin-xu">Weilin Xu</a>
    
  </span>
  
  
</div>


<h2 id="uva-group-dinner-at-ieee-security-and-privacy-2018">UVA Group Dinner at IEEE Security and Privacy 2018</h2>
<p>Including our newest faculty member, <a href="https://www.cs.purdue.edu/homes/kwon58/#summary">Yongwhi Kwon</a>, joining UVA in Fall 2018!<br /></p>
<center><br />
<a href="/images/srg2018/ORG_DSC07202.jpg"><img src="/images/srg2018/ORG_DSC07202.jpg" width="680"></a><br />
<small>Yuan Tian, Fnu Suya, Mainuddin Jonas, Yongwhi Kwon, David Evans, Weihang Wang, Aihua&nbsp;Chen,&nbsp;Weilin&nbsp;Xu</small><br />
</center>
</p>
<p>
## Poster Session
<table width="100%">
<tr valign="top">
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180521_193906.jpg"><img src="/images/srg2018/IMG_20180521_193906-3.jpg" height="360"></a><br />
Fnu Suya (with Yuan Tian and David Evans), <em>Adversaries Don’t Care About Averages: Batch Attacks on Black-Box Classifiers</em> <a href="https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper37-poster-abstract.pdf">[PDF]</a>
</td>
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180521_193914.jpg"><img src="/images/srg2018/IMG_20180521_193914-2.jpg" height="360"></a><br />
Mainuddin Jonas (with David Evans), <em>Enhancing Adversarial Example Defenses Using Internal Layers</em> <a href="https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper29-poster-abstract.pdf">[PDF]</a>
</td>
</tr>
<tr valign="top">
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180522_153017.jpg"><img src="/images/srg2018/IMG_20180522_153017-2.jpg" height="300"></a>
</td>
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180522_153109.jpg"><img src="/images/srg2018/IMG_20180522_153109-2.jpg" height="300"></a>
</td>
</tr>
</table>

	

    
    <h2><a href="/lessons-from-the-last-3000-years-of-adversarial-examples/">Lessons from the Last 3000 Years of Adversarial Examples</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-05-15 00:00:00 &#43;0000 UTC" itemprop="datePublished">15 May 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/china">China</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/huawei">Huawei</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/battista-biggio">Battista Biggio</a>
    
  </span>
  
  
</div>


<p>I spoke on <em>Lessons from the Last 3000 Years of Adversarial Examples</em> at Huawei’s Strategy and Technology Workshop in Shenzhen, China, 15 May 2018.  </p></p>
<p>
<script async class="speakerdeck-embed" data-id="3de1c0f163b44ab18e4928c58eea706e" data-ratio="1.77777777777778" src="http://speakerdeck.com/assets/embed.js"></script>
</p>
<p>
We also got to tour Huawei&#8217;s new research and development campus, under construction about 40 minutes from Shenzhen. It is pretty close to Disneyland, with its own railroad and villages themed after different European cities (Paris, Bologna, etc.).<br />
<center><br />
<a href="/images/029.jpg"><img src="/images/029.jpg" width="650"></a><br />
Huawei&#8217;s New Research and Development Campus [<a href="https://photos.app.goo.gl/YqGfaC6fqNAsywzd2">More Pictures</a>]<br />
</center></p>
<p class="text-right"><a href="/lessons-from-the-last-3000-years-of-adversarial-examples/">Read More…</a></p>
	

    
    <h2><a href="/feature-squeezing-at-ndss/">Feature Squeezing at NDSS</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-02-25 00:00:00 &#43;0000 UTC" itemprop="datePublished">25 February 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/feature-squeezing">feature squeezing</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/weilin-xu">Weilin Xu</a>
    
  </span>
  
  
</div>


<p>Weilin Xu presented <em>Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks</em> at the <a href="http://www.ndss-symposium.org/ndss2018/">Network and Distributed System Security Symposium 2018</a>. San Diego, CA. 21 February 2018.<br /></p>
<center><br />
<script async class="speakerdeck-embed" data-id="cdfcf454436240e4ab1a6c4d594e5c7a" data-ratio="1.77777777777778" src="http://speakerdeck.com/assets/embed.js"></script><br />
</center></p>
<p>
Paper: Weilin Xu, David Evans, Yanjun Qi. <em>Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks</em>. NDSS 2018. [<a href="https://evademl.org/docs/featuresqueezing.pdf">PDF</a>]</p>
<p>Project Site: <a href="https://evademl.org/squeezing">EvadeML.org</a></p></p>

	

    
    <h2><a href="/older-posts/">Older Posts</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-02-24 00:00:00 &#43;0000 UTC" itemprop="datePublished">24 February 2018</time>
  </span>
  
  
  
  
</div>


<p>Older posts have not been moved into this new blog, but are still
available here:</p>
<ul>
<li><a href="/2017.html">2017</a></li>
<li><a href="/2016.html">2016</a></li>
<li><a href="/2015.html">2015</a></li>
<li><a href="/2014.html">2014</a></li>
<li><a href="/2013.html">2013</a></li>
<li><a href="/2012.html">2012</a></li>
<li><a href="/2011.html">2011</a></li>
<li><a href="/2010.html">2010</a></li>
<li><a href="/2009.html">2009</a></li>
<li><a href="/2008.html">2008</a></li>
</ul>

	

    
    <div class="row">
  <div class="column small-12">
    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li><span>Page 10 of 10</span></li>      
      
      <li class="arrow" aria-disabled="true"><a href="/post/page/9/"><em>Newer<span class="show-for-sr"> blog entries</span></em>:&nbsp;&raquo;</a></li>
      
    </ul>    
    All Posts by <a href="//uvasrg.github.io/categories">Category</a> or <a href="//uvasrg.github.io/tags">Tags</a>.

  </div>
</div>

</div>
</div>
</div>

    </main>
    
    
    <footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>

    
    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
