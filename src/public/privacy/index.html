<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title> | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      



	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      
<div class="row">
  <div class="column small-12 medium-10 medium-offset-1 end large-8 large-offset-0">
    <article class="article" itemscope itemtype="http://schema.org/Article">
      
      <h1 itemprop="name"></h1>
      <div class="post-body" itemprop="articleBody">
        <h1 id="machine-learning-privacy">Machine Learning Privacy</h1>
<p>Our research focuses on understanding and mitigating privacy risks
associated with machine learning. This includes both <em>data privacy</em>
(protecting sensitive data used to train a model during the collection
and learning process) and <em>inference privacy</em> (limiting what can be
inferred about sensitive training data from an exposed model).</p>
<p><a href="/privacyreadinggroup"><strong>Privacy Reading Group</strong></a></p>
<h1 id="inference-privacy">Inference Privacy</h1>
<p>These blog posts (in forward chronological order) summarize our recent
work on evaluating inference leakage from models:</p>
<ul>
<li>
<p><a href="https://uvasrg.github.io/evaluating-differentially-private-machine-learning-in-practice/"><em>Evaluating Differentially Private Machine Learning in Practice</em></a> (<a href="https://arxiv.org/abs/1902.08874">USENIX Security 2019 Paper</a>)</p>
</li>
<li>
<p><a href="https://uvasrg.github.io/merlin-morgan-and-the-importance-of-thresholds-and-priors/"><em>Merlin, Morgan, and the Importance of Thresholds and Priors</em></a> (<a href="https://arxiv.org/abs/2005.10881">PETS 2021 Paper</a>)</p>
</li>
<li>
<p><a href="https://uvasrg.github.io/on-the-risks-of-distribution-inference/"><em>On the Risks of Distribution Inference</em></a> (<a href="https://arxiv.org/abs/2109.06024">PETS 2022 Paper</a>)</p>
</li>
<li>
<p><a href="/dissecting-distribution-inference/"><em>Dissecting Distribution Inference</em></a> (<a href="https://satml.org/">SatML 2023 Paper</a>)</p>
</li>
<li>
<p><a href="/cvpr-2023-manipulating-transfer-learning-for-property-inference/"><em>Manipulating Transfer Learning for Property Inference</em></a> (<a href="https://arxiv.org/abs/2303.11643">CVPR 2023 Paper</a>)</p>
</li>
</ul>
<h3 id="publications">Publications</h3>
<p>SRG papers on privacy-preserving machine learning (in reverse chronological order):</p>
<p><a href="https://arxiv.org/abs/1910.13659"><em>Efficient Privacy-Preserving Stochastic Nonconvex Optimization</em></a>. Lingxiao Wang, Bargav Jayaraman, David Evans, Quanquan Gu. In <a href="https://www.auai.org/uai2023/"><em>39<sup>th</sup> Conference on Uncertainty in Artificial Intelligence</em></a> (UAI). Pittsburgh, PA. July 2023. [<a href="https://arxiv.org/abs/1910.13659">Arxiv</a>]</p>
<p><a href="https://arxiv.org/abs/2303.11643"><Em>Manipulating Transfer
Learning for Property Inference</em></a>. Yulong Tian, Fnu Suya, Anshuman Suri, Fengyuan Xu, David Evans. In <a href="https://cvpr2023.thecvf.com/"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition 2023</em></a> (CVPR),
Vancouver, Canada. June 2023. [<a href="https://arxiv.org/abs/2303.11643">Arxiv</a>] [<a href="https://github.com/yulongt23/Transfer-Inference">Code</a>]</p>
<p><a href="https://arxiv.org/abs/2212.10986"><em>SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning</em></a>.
Ahmed Salem, Giovanni Cherubin, David Evans, Boris Köpf, Andrew
Paverd, Anshuman Suri, Shruti Tople, Santiago
Zanella-Begueli. In <a href="https://sp2023.ieee-security.org/"><em>44<sup>th</sup>
IEEE Symposium on Security and Privacy</em></a>
(Oakland). May 2023. [<a href="https://arxiv.org/abs/2212.10986">Arxiv</a>] [<a href="/sok-let-the-privacy-games-begin-a-unified-treatment-of-data-inference-privacy-in-machine-learning/">Video</a>]</p>
<p><a href="https://arxiv.org/abs/2212.07591"><em>Dissecting Distribution
Inference</em></a>. Anshuman Suri, Yifu Lu, Yanjin Chen, David
Evans. In <a href="https://satml.org/"><em>IEEE Conference on Secure and
Trustworthy Machine Learning</em></a> (SaTML). Raleigh, North
Carolina, 8–10 February 2023. [<a href="https://arxiv.org/abs/2212.07591">Arxiv</a>] [<A href="https://uvasrg.github.io/dissecting-distribution-inference/">Blog</a>] [<a href="https://github.com/iamgroot42/dissecting_distribution_inference">Code</a>]</p>
<p><a href="https://arxiv.org/abs/2209.01292"><em>Are Attribute Inference
Attacks Just Imputation?</em></a>. Bargav Jayaraman and David
Evans. In <a href="https://www.sigsac.org/ccs/CCS2022/">29<sup>th</sup> ACM
Conference on Computer and Communications Security</a>
(CCS). November
2022. [<a href="https://arxiv.org/abs/2209.01292">Arxiv</a>]
[<a href="https://github.com/bargavj/EvaluatingDPML">Code</a>]</p>
<p><a href="https://arxiv.org/abs/2109.06024"><em>Formalizing and
Estimating Distribution Inference Risks
</em></a>. Anshuman Suri and David
Evans. In <a href="https://petsymposium.org/2022/">Privacy Enhancing
Technologies Symposium</a> (PETS). July 2022. (Also published
in <a href="https://petsymposium.org/popets/2022/">Proceedings on
Privacy Enhancing Technologies</a>, Issue 4, 2022.)
[<a href="https://arxiv.org/abs/2109.06024">Arxiv</a>]
[<a href="https://github.com/iamgroot42/FormEstDistRisks">Code</a>]</p>
<p><a href="https://arxiv.org/abs/2005.10881"><em>
Revisiting Membership Inference Under Realistic Assumptions</em></a>. Bargav Jayaraman, Lingxiao Wang, Katherine Knipmeyer, Quanquan Gu, and David
Evans. In <a href="https://www.petsymposium.org/2021/">Proceedings on Privacy Enhancing Technologies</a>
(PETS). July
2021. [<a href="https://arxiv.org/abs/2005.10881">Arxiv</a>]
[<A href="https://arxiv.org/pdf/2005.10881.pdf">PDF</a>] [<a href="https://github.com/bargavj/EvaluatingDPML">Code</a>]</p>
<p><em><a href="usenix2019/">Evaluating Differentially Private Machine
Learning in Practice</a></em>. Bargav Jayaraman and David Evans. In <a
href="https://www.usenix.org/conference/usenixsecurity19"><em>28<sup>th</sup>
USENIX Security Symposium</em></a>. Santa Clara. August 2019.
[<a href="usenix2019/evaluatingdp.pdf">PDF</a>]
[<a href="https://arxiv.org/abs/1902.08874">arXiv</a>]
[<A href="https://github.com/bargavj/EvaluatingDPML">code</a>]</p>
<p><a href="https://oblivc.org/ppml/"><em>Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization</em></a>. <a href="https://bargavjayaraman.github.io/">Bargav Jayaraman</a>, Lingxiao Wang, <a href="http://web.cs.ucla.edu/~qgu/research.html">Quanquan Gu</a>, and <a href="https://www.cs.virginia.edu/evans">David Evans</a>. In <em>32nd Conference on Neural Information Processing Systems</em> (NeurIPS 2018), Montréal, Canada. May 2018. (<a href="https://github.com/bargavj/distributedMachineLearning">Code</a>, <a href="https://oblivc.org/docs/neurips2018.pdf">Paper</a>)</p>
<!-- 

# Privacy-Preserving Machine Learning

_Distributed learning_ (sometimes marketed as _federated learning_)
allows a group of independent data owners to collaboratively learn a
model over their data sets without exposing their private data.

## Projects

[**Integrating Multi-Party Computation with Differential Privacy**](https://oblivc.org/ppml/) ([Code](https://github.com/bargavj/distributedMachineLearning), [NeurIPS 2018 Paper](https://oblivc.org/docs/neurips2018.pdf)  
[Bargav Jayaraman](https://bargavjayaraman.github.io/), Lingxiao Wang, [Quanquan Gu](http://web.cs.ucla.edu/~qgu/research.html)

**Privacy-preserving Medical Decision Systems**  
[Josephine Lamp](https://www.josephinelamp.com/) and [Lu Feng](http://www.cs.virginia.edu/~lufeng/index.html)

**Privacy-Preserving Nonconvex Optimization** [[Preprint](https://arxiv.org/abs/1910.13659)]  
Lingxiao Wang, [Bargav Jayaraman](https://bargavjayaraman.github.io/), [Quanquan Gu](http://web.cs.ucla.edu/~qgu/research.html)

-->

      </div>

      <meta itemprop="wordCount" content="410">
      <meta itemprop="datePublished" content="0001-01-01">
      <meta itemprop="url" content="//uvasrg.github.io/privacy/">
    </article>


  </div>
</div>

    </main>
    
    
<footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>


    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
