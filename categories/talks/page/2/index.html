<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>Talks | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      
        <p class="groupstyle">Security and Privacy Research</br>at the University of Virginia</p>
	      
	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      
<div style="margin-top:16px; margin-left: auto; margin-right: auto; max-width: 800px;">
<div class="row">
  <div class="column small-12">
    
    
    <h2><a href="/microsoft-security-data-science-colloquium-inference-privacy-in-theory-and-practice/">Microsoft Security Data Science Colloquium: Inference Privacy in Theory and Practice</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-12-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">1 December 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/bargav-jayaraman">Bargav Jayaraman</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/microsoft">Microsoft</a>
    
  </span>
  
  
</div>


<p>Here are the slides for my talk at the Microsoft Security Data Science Colloquium:<br>
<a href="https://www.dropbox.com/s/698cuvee81clx1q/inference-privacy-share.pdf?dl=0"><em>When Models Learn Too Much: Inference Privacy in Theory and Practice</em> [PDF]</a></p>
<center>
<a href="https://www.dropbox.com/s/698cuvee81clx1q/inference-privacy-share.pdf?dl=0">
<img src="/images/inferenceprivacytitle.png" width=65%>
</a>
</center>
<p>The talk is mostly about Bargav Jayaraman&rsquo;s work (with Katherine Knipmeyer, Lingxiao Wang, and Quanquan Gu) on evaluating privacy:</p>
<ul>
<li><a href="/merlin-morgan-and-the-importance-of-thresholds-and-priors/"><em>Merlin, Morgan, and the Importance of Thresholds and Priors</em></a></li>
<li><a href="/evaluating-differentially-private-machine-learning-in-practice/"><em>Evaluating Differentially Private Machine Learning in Practice</em></a></li>
</ul>

	

    
    <h2><a href="/jobs-for-humans-2029-2059/">Jobs for Humans, 2029-2059</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-10-30 00:00:00 &#43;0000 UTC" itemprop="datePublished">30 October 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/artificial-intelligence">artificial intelligence</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/outreach">outreach</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/education">education</a>
    
  </span>
  
  
</div>


<p>I was honored to particilate in a panel at an event on
<a href="https://aohdc.org/adulteducationandai/"><em>Adult Education in the Age of Artificial Intelligence</em></a> that was run by <a href="https://www.thegreatcoursesplus.com/">The Great Courses</a> as a fundraiser for the <a href="https://aohdc.org/">Academy of Hope</a>, an adult public charter school in Washington, D.C.</p>
<p>I spoke first, following a few introductory talks, and was followed by
Nicole Smith and Ellen Scully-Russ, and a keynote from Dexter Manley,
Super Bowl winner with the Washington Redskins. After a short break,
Kavitha Cardoza moderated a very interesting panel discussion. A
recording of the talk and rest of the event is supposed to be
available to Great Courses Plus subscribers.</p>
<p class="text-right"><a href="/jobs-for-humans-2029-2059/">Read More…</a></p>
	

    
    <h2><a href="/fosad2019/">FOSAD Trustworthy Machine Learning Mini-Course</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-28 00:00:00 &#43;0000 UTC" itemprop="datePublished">28 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>
    
  </span>
  
  
</div>


<p>I taught a mini-course on <em>Trustworthy Machine Learning</em> at the <a href="http://www.sti.uniurb.it/events/fosad19/"><em>19th
International School on Foundations of Security Analysis and
Design</em></a> in Bertinoro, Italy.</p>
<center><a href="/images/bertinoro-big.jpg"><img src="/images/bertinoro.jpg" width="90%"></a></center>
<p>Slides from my three (two-hour) lectures are posted below, along with
some links to relevant papers and resources.</p>
<h2 id="class-1-introductionattacks">Class 1: Introduction/Attacks</h2>
<center>
<script async class="speakerdeck-embed" data-id="0ad1775bcc244876ac4df1880a864e78" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
</center>
<p>The PDF malware evasion attack is described in this paper:</p>
<blockquote>
Weilin Xu, Yanjun Qi, and David Evans. 
<em><a href="https://www.cs.virginia.edu/evans/pubs/ndss2016/">Automatically Evading Classifiers: A Case Study on PDF Malware Classifiers</a></em>.
<a href="https://www.internetsociety.org/events/ndss-symposium-2016"><em>Network and Distributed System Security Symposium</em></a> (NDSS). San Diego, CA. 21-24 February 2016. [<a href="https://www.cs.virginia.edu/evans/pubs/ndss2016/evademl.pdf">PDF</a>] [<a href="https://evademl.org/gpevasion/">EvadeML.org</a>]
</blockquote>
<h2 id="class-2-defenses">Class 2: Defenses</h2>
<center>
<script async class="speakerdeck-embed" data-id="cf560cce9e4b418397d2df3429ddc8f9" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
</center>
<p>This paper describes the feature squeezing framework:</p>
<p class="text-right"><a href="/fosad2019/">Read More…</a></p>
	

    
    <h2><a href="/google-security-and-privacy-workshop/">Google Security and Privacy Workshop</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-25 00:00:00 &#43;0000 UTC" itemprop="datePublished">25 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/google">Google</a>
    
  </span>
  
  
</div>


<p>I presented a short talk at a workshop at Google on <em>Adversarial ML: Closing Gaps between Theory and Practice</em> (mostly fun for the <a href="https://www.youtube.com/watch?v=TVmjjfTvnFs">movie of me trying to solve Google&rsquo;s CAPTCHA</a> on the last slide):</p>
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTKeMueFNQPz0Pms4EGKoYOXVEg92IBi55babPKG5WRrhHRR2PmIYwZIyLsZ11ucKSahqjjp3Zxd5i3/embed?start=true&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
<p>Getting the actual screencast to fit into the limited time for this talk challenged the limits of my video editing skills.</p>
<center>
<img src="/images/googledonuts.jpg" width="90%"><br>
I can say with some confidence, Google does donuts much better than they <a href="https://freedom-to-tinker.com/2019/08/23/deconstructing-googles-excuses-on-tracking-protection/">do cookies</a>!
</center>

	

    
    <h2><a href="/google-federated-privacy-2019-the-dragon-in-the-room/">Google Federated Privacy 2019: The Dragon in the Room</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-06-22 00:00:00 &#43;0000 UTC" itemprop="datePublished">22 June 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/google">Google</a>
    
  </span>
  
  
</div>


<p>I&rsquo;m back from a very interesting <a href="https://sites.google.com/view/federated-learning-2019/"><em>Workshop on Federated Learning and
Analytics</em></a>
that was organized by <a href="https://ai.google/research/people/PeterKairouz">Peter
Kairouz</a> and <a href="https://ai.google/research/people/author35837">Brendan
McMahan</a> from Google&rsquo;s
federated learning team and was held at Google Seattle.</p>
<p>For the first part of my talk, I covered Bargav&rsquo;s work on <a href="http://www.cs.virginia.edu/~evans/pubs/usenix2019/">evaluating
differentially private machine
learning</a>, but I
reserved the last few minutes of my talk to address the cognitive
dissonance I felt being at a Google meeting on privacy.</p>
<div class="row">
  <div class="column small-12 medium-6">
  <a href="/images/googleprivacy2019/slides-full/Slide01.png"><img src="/images/googleprivacy2019/slides/Slide01.png"></a>
  </div>
  <div class="column small-12 medium-6">
<p>
I don’t want to offend anyone, and want to preface this by saying I
have lots of friends and former students who work for Google, people
that I greatly admire and respect – so I want to raise the cognitive
dissonance I have being at a “privacy” meeting run by Google, in the
hopes that people at Google actually do think about privacy and will
able to convince me how wrong I am.
</p>
<p class="text-right"><a href="/google-federated-privacy-2019-the-dragon-in-the-room/">Read More…</a></p>
	

    
    <h2><a href="/jason-spring-meeting-adversarial-machine-learning/">JASON Spring Meeting: Adversarial Machine Learning</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-04-27 00:00:00 &#43;0000 UTC" itemprop="datePublished">27 April 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>
    
  </span>
  
  
</div>


<center>
<a href="/images/JASON/IMG_20190429_171641.jpg"><img src="/images/JASON/IMG_20190429_171641-2.jpg" width="70%"> </a>
</center>
<p>I had the privilege of speaking at the JASON Spring Meeting,
undoubtably one of the most diverse meetings I&rsquo;ve been part of with
talks on hypersonic signatures (from my DSSG 2008-2009 colleague, Ian
Boyd), FBI DNA, nuclear proliferation in Iran, engineering biological
materials, and the 2020 census (including a very interesting
presentatino from John Abowd on the differential privacy mechanisms
they have developed and evaluated). (Unfortunately, my lack of
security clearance kept me out of the SCIF used for the talks on
quantum computing and more sensitive topics).</p>
<p class="text-right"><a href="/jason-spring-meeting-adversarial-machine-learning/">Read More…</a></p>
	

    
    <h2><a href="/can-machine-learning-ever-be-trustworthy/">Can Machine Learning Ever Be Trustworthy?</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-12-07 00:00:00 &#43;0000 UTC" itemprop="datePublished">7 December 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/talks">talks</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/university-of-maryland">University of Maryland</a>
    
  </span>
  
  
</div>


<p>I gave the <a href="https://ece.umd.edu/events/distinguished-colloquium-series"><em>Booz Allen Hamilton Distinguished Colloquium</em></a> at the
University of Maryland on <em>Can Machine Learning Ever Be Trustworthy?</em>.</p>
<center>
[Video](https://vid.umd.edu/detsmediasite/Play/e8009558850944bfb2cac477f8d741711d?catalog=74740199-303c-49a2-9025-2dee0a195650) &middot;
[SpeakerDeck](https://speakerdeck.com/evansuva/can-machine-learning-ever-be-trustworthy)
<p><a href="/images/umd2018/umd.jpg"><img src="/images/umd2018/umd.jpg" width="80%"></a></p>
</center>
   <div class="abstract">
<center><b>Abstract</b></center>
Machine learning has produced extraordinary results over the past few years, and machine learning systems are rapidly being deployed for
critical tasks, even in adversarial environments.  This talk will survey some of the reasons building trustworthy machine learning
systems is inherently impossible, and dive into some recent research on adversarial examples. Adversarial examples are inputs crafted
deliberately to fool a machine learning system, often by making small, but targeted perturbations, starting from a natural seed example. Over the past few years, there has been an explosion of research in adversarial examples but we are only beginning to understand their
mysteries and just taking the first steps towards principled and effective defenses. The general problem of adversarial examples, however, has been at the core of information security for thousands of years. In this talk, I'll look at some of the long-forgotten lessons
from that quest, unravel the huge gulf between theory and practice in adversarial machine learning, and speculate on paths toward
trustworthy machine learning systems.
   </div>

	

    
    <h2><a href="/mutually-assured-destruction-and-the-impending-ai-apocalypse/">Mutually Assured Destruction and the Impending AI Apocalypse</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-08-13 00:00:00 &#43;0000 UTC" itemprop="datePublished">13 August 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/woot">WOOT</a>
    
  </span>
  
  
</div>


<p>I gave a keynote talk at <a href="https://www.usenix.org/conference/woot18/workshop-program">USENIX Workshop of Offensive Technologies</a>, Baltimore, Maryland, 13 August 2018. </p></p>
<p>The title and abstract are what I provided for the WOOT program, but unfortunately (or maybe fortunately for humanity!) I wasn&#8217;t able to actually figure out a talk to match the title and abstract I provided.</p>
<blockquote><p>
The history of security includes a long series of arms races, where a new technology emerges and is subsequently developed and exploited by both defenders and attackers. Over the past few years, &#8220;Artificial Intelligence&#8221; has re-emerged as a potentially transformative technology, and deep learning in particular has produced a barrage of amazing results. We are in the very early stages of understanding the potential of this technology in security, but more worryingly, seeing how it may be exploited by malicious individuals and powerful organizations. In this talk, I&#8217;ll look at what lessons might be learned from previous security arms races, consider how asymmetries in AI may be exploited by attackers and defenders, touch on some recent work in adversarial machine learning, and hopefully help progress-loving Luddites figure out how to survive in a world overrun by AI doppelgängers, GAN gangs, and gibbon-impersonating pandas.
</p>
<p class="text-right"><a href="/mutually-assured-destruction-and-the-impending-ai-apocalypse/">Read More…</a></p>
	

    
    <h2><a href="/dls-keynote-is-adversarial-examples-an-adversarial-example/">DLS Keynote: Is &#39;adversarial examples&#39; an Adversarial Example?</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-05-29 00:00:00 &#43;0000 UTC" itemprop="datePublished">29 May 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/talks">talks</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/videos">videos</a>
    
  </span>
  
  
</div>


<p>I gave a keynote talk at the <a href="https://www.ieee-security.org/TC/SPW2018/DLS/#"><em>1st Deep Learning and Security Workshop</em></a> (co-located with the 39th <em>IEEE Symposium on Security and Privacy</em>). San Francisco, California. 24 May 2018</p></p>
<p><center><br />
<iframe width="640" height="360" src="https://www.youtube-nocookie.com/embed/sFhD6ABghf8?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</p>
<p>
<script async class="speakerdeck-embed"
	data-id="9d2c5bf9b3444a8a992762f5cd6ea7fe"
	data-ratio="1.77777777777778" src="http://speakerdeck.com/assets/embed.js"></script><br />
</center>
</p>
<p>
<center><br />
<b>Abstract</b><br />
</center></p>
<p>
Over the past few years, there has been an explosion of research in security of machine learning and on adversarial examples in particular. Although this is in many ways a new and immature research area, the general problem of adversarial examples has been a core problem in information security for thousands of years. In this talk, I&#8217;ll look at some of the long-forgotten lessons from that quest and attempt to understand what, if anything, has changed now we are in the era of deep learning classifiers. I will survey the prevailing definitions for &#8220;adversarial examples&#8221;, argue that those definitions are unlikely to be the right ones, and raise questions about whether those definitions are leading us astray.</p>
<p class="text-right"><a href="/dls-keynote-is-adversarial-examples-an-adversarial-example/">Read More…</a></p>
	

    
    <h2><a href="/lessons-from-the-last-3000-years-of-adversarial-examples/">Lessons from the Last 3000 Years of Adversarial Examples</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-05-15 00:00:00 &#43;0000 UTC" itemprop="datePublished">15 May 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/china">China</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/huawei">Huawei</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/battista-biggio">Battista Biggio</a>
    
  </span>
  
  
</div>


<p>I spoke on <em>Lessons from the Last 3000 Years of Adversarial Examples</em> at Huawei’s Strategy and Technology Workshop in Shenzhen, China, 15 May 2018.  </p></p>
<p>
<script async class="speakerdeck-embed" data-id="3de1c0f163b44ab18e4928c58eea706e" data-ratio="1.77777777777778" src="http://speakerdeck.com/assets/embed.js"></script>
</p>
<p>
We also got to tour Huawei&#8217;s new research and development campus, under construction about 40 minutes from Shenzhen. It is pretty close to Disneyland, with its own railroad and villages themed after different European cities (Paris, Bologna, etc.).<br />
<center><br />
<a href="/images/029.jpg"><img src="/images/029.jpg" width="650"></a><br />
Huawei&#8217;s New Research and Development Campus [<a href="https://photos.app.goo.gl/YqGfaC6fqNAsywzd2">More Pictures</a>]<br />
</center></p>
<p class="text-right"><a href="/lessons-from-the-last-3000-years-of-adversarial-examples/">Read More…</a></p>
	

    
    <div class="row">
  <div class="column small-12">
    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li class="arrow" aria-disabled="true"><a href="/categories/talks/page/3/">&laquo; <em>Older<span class="show-for-sr"> blog entries</span></em></a></li>
      
      <li><span>Page 2 of 3</span></li>      
      
      <li class="arrow" aria-disabled="true"><a href="/categories/talks/"><em>Newer<span class="show-for-sr"> blog entries</span></em>:&nbsp;&raquo;</a></li>
      
    </ul>    
    All Posts by <a href="//uvasrg.github.io/categories">Category</a> or <a href="//uvasrg.github.io/tags">Tags</a>.

  </div>
</div>

  </div>
</div>
</div>

    </main>
    
    
    <footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>

    
    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
