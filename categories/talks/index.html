<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>talks | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      
	      
	    </div>
	  </div>
	    
	  
	    <div class="top-bar" id="site-menu" >	      
	      <div class="top-bar-title show-for-medium site-title">
		<a href="//uvasrg.github.io/">Security Research Group</a>
	      </div>
	      <div class="top-bar-left">
		<ul class="menu vertical medium-horizontal">
		  
		  
		</ul>
	      </div>
	      <div class="top-bar-right show-for-medium">
		
	         <p class="groupstyle">Security and Privacy Research</br>at the University of Virginia</p>
		
	      </div>
	    </div>
	  
	</nav>
      
    </header>
    
    <main>
      
<div style="margin-top:16px; margin-left: auto; margin-right: auto; max-width: 800px;">
<div class="row">
  <div class="column small-12">
    
    
    <h2><a href="/codaspy-2021-keynote-when-models-learn-too-much/">Codaspy 2021 Keynote: When Models Learn Too Much</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2021-04-26 00:00:00 &#43;0000 UTC" itemprop="datePublished">26 April 2021</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/bargav-jayaraman">Bargav Jayaraman</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/anshuman-suri">Anshuman Suri</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/katherine-knipmeyer">Katherine Knipmeyer</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/inference-privacy">inference privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>
    
  </span>
  
  
</div>


<p>Here are the slides for my talk at the
<a href="http://www.codaspy.org/2021/program.html">11th ACM Conference on Data and Application Security and Privacy</a>:
<a href="https://www.dropbox.com/s/6wzloxuai709s0k/codaspy-post.pdf?dl=0"><em>When Models Learn Too Much</em> [PDF]</a></p>
<p>The talk includes Bargav Jayaraman&rsquo;s work (with Katherine Knipmeyer, Lingxiao Wang, and Quanquan Gu) on evaluating privacy in machine learning (as well as more recent work by Anshuman Suri on property inference attacks, and Bargav on attribute inference and imputation):</p>
<ul>
<li><a href="/merlin-morgan-and-the-importance-of-thresholds-and-priors/"><em>Merlin, Morgan, and the Importance of Thresholds and Priors</em></a></li>
<li><a href="/evaluating-differentially-private-machine-learning-in-practice/"><em>Evaluating Differentially Private Machine Learning in Practice</em></a></li>
</ul>

	

    
    <h2><a href="/crysp-talk-when-models-learn-too-much/">CrySP Talk: When Models Learn Too Much</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2021-04-05 00:00:00 &#43;0000 UTC" itemprop="datePublished">5 April 2021</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/differential-privacy">differential privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/videos">videos</a>
    
  </span>
  
  
</div>


I gave a talko on When Models Learn Too Much at the University of Waterloo (virtually) in the CrySP Speaker Series on Privacy (29 March 2021):
    Abstract  Statistical machine learning uses training data to produce models that capture patterns in that data. When models are trained on private data, such as medical records or personal emails, there is a risk that those models not only learn the hoped-for patterns, but will also learn and expose sensitive information about their training data.
<p class="text-right"><a href="/crysp-talk-when-models-learn-too-much/">Read More…</a></p>
	

    
    <h2><a href="/virginia-consumer-data-protection-act/">Virginia Consumer Data Protection Act</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2021-02-19 00:00:00 &#43;0000 UTC" itemprop="datePublished">19 February 2021</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/law">law</a>
    
  </span>
  
  
</div>


<p><a href="https://www.josephinelamp.com/">Josephine Lamp</a> presented on the new data privacy law that is pending in Virginia (it still needs a few steps including expected signing by governor, but likely to go into effect Jan 1, 2023): <a href="https://www.dropbox.com/s/1epulyhc30wd239/cdpa.pdf?dl=0">Slides (PDF)</a></p>
<p>This article provides a summary of the law: <a href="https://www.natlawreview.com/article/virginia-passes-consumer-privacy-law-other-states-may-follow"><em>Virginia Passes Consumer Privacy Law; Other States May Follow</em></a>, National Law Review, 17 February 2021.</p>
<p>The law itself is here: <a href="https://lis.virginia.gov/cgi-bin/legp604.exe?211+ful+SB1392">SB 1392: Consumer Data Protection Act</a></p>

	

    
    <h2><a href="/microsoft-security-data-science-colloquium-inference-privacy-in-theory-and-practice/">Microsoft Security Data Science Colloquium: Inference Privacy in Theory and Practice</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-12-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">1 December 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/bargav-jayaraman">Bargav Jayaraman</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>
    
  </span>
  
  
</div>


<p>Here are the slides for my talk at the Microsoft Security Data Science Colloquium:<br>
<a href="https://www.dropbox.com/s/698cuvee81clx1q/inference-privacy-share.pdf?dl=0"><em>When Models Learn Too Much: Inference Privacy in Theory and Practice</em> [PDF]</a></p>
<center>
<a href="https://www.dropbox.com/s/698cuvee81clx1q/inference-privacy-share.pdf?dl=0">
<img src="/images/inferenceprivacytitle.png" width=65%>
</a>
</center>
<p>The talk is mostly about Bargav Jayaraman&rsquo;s work (with Katherine Knipmeyer, Lingxiao Wang, and Quanquan Gu) on evaluating privacy:</p>
<ul>
<li><a href="/merlin-morgan-and-the-importance-of-thresholds-and-priors/"><em>Merlin, Morgan, and the Importance of Thresholds and Priors</em></a></li>
<li><a href="/evaluating-differentially-private-machine-learning-in-practice/"><em>Evaluating Differentially Private Machine Learning in Practice</em></a></li>
</ul>

	

    
    <h2><a href="/jobs-for-humans-2029-2059/">Jobs for Humans, 2029-2059</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-10-30 00:00:00 &#43;0000 UTC" itemprop="datePublished">30 October 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/artificial-intelligence">artificial intelligence</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/outreach">outreach</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/education">education</a>
    
  </span>
  
  
</div>


I was honored to particilate in a panel at an event on Adult Education in the Age of Artificial Intelligence that was run by The Great Courses as a fundraiser for the Academy of Hope, an adult public charter school in Washington, D.C.
I spoke first, following a few introductory talks, and was followed by Nicole Smith and Ellen Scully-Russ, and a keynote from Dexter Manley, Super Bowl winner with the Washington Redskins.
<p class="text-right"><a href="/jobs-for-humans-2029-2059/">Read More…</a></p>
	

    
    <h2><a href="/fosad2019/">FOSAD Trustworthy Machine Learning Mini-Course</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-28 00:00:00 &#43;0000 UTC" itemprop="datePublished">28 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>
    
  </span>
  
  
</div>


I taught a mini-course on Trustworthy Machine Learning at the 19th International School on Foundations of Security Analysis and Design in Bertinoro, Italy.
 Slides from my three (two-hour) lectures are posted below, along with some links to relevant papers and resources.
Class 1: Introduction/Attacks    The PDF malware evasion attack is described in this paper:
 Weilin Xu, Yanjun Qi, and David Evans. Automatically Evading Classifiers: A Case Study on PDF Malware Classifiers.
<p class="text-right"><a href="/fosad2019/">Read More…</a></p>
	

    
    <h2><a href="/google-security-and-privacy-workshop/">Google Security and Privacy Workshop</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-25 00:00:00 &#43;0000 UTC" itemprop="datePublished">25 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/google">Google</a>
    
  </span>
  
  
</div>


I presented a short talk at a workshop at Google on Adversarial ML: Closing Gaps between Theory and Practice (mostly fun for the movie of me trying to solve Google&rsquo;s CAPTCHA on the last slide):
 Getting the actual screencast to fit into the limited time for this talk challenged the limits of my video editing skills.
 I can say with some confidence, Google does donuts much better than they do cookies!
<p class="text-right"><a href="/google-security-and-privacy-workshop/">Read More…</a></p>
	

    
    <h2><a href="/google-federated-privacy-2019-the-dragon-in-the-room/">Google Federated Privacy 2019: The Dragon in the Room</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-06-22 00:00:00 &#43;0000 UTC" itemprop="datePublished">22 June 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/google">Google</a>
    
  </span>
  
  
</div>


I&rsquo;m back from a very interesting Workshop on Federated Learning and Analytics that was organized by Peter Kairouz and Brendan McMahan from Google&rsquo;s federated learning team and was held at Google Seattle.
For the first part of my talk, I covered Bargav&rsquo;s work on evaluating differentially private machine learning, but I reserved the last few minutes of my talk to address the cognitive dissonance I felt being at a Google meeting on privacy.
<p class="text-right"><a href="/google-federated-privacy-2019-the-dragon-in-the-room/">Read More…</a></p>
	

    
    <h2><a href="/jason-spring-meeting-adversarial-machine-learning/">JASON Spring Meeting: Adversarial Machine Learning</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-04-27 00:00:00 &#43;0000 UTC" itemprop="datePublished">27 April 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>
    
  </span>
  
  
</div>


I had the privilege of speaking at the JASON Spring Meeting, undoubtably one of the most diverse meetings I&rsquo;ve been part of with talks on hypersonic signatures (from my DSSG 2008-2009 colleague, Ian Boyd), FBI DNA, nuclear proliferation in Iran, engineering biological materials, and the 2020 census (including a very interesting presentatino from John Abowd on the differential privacy mechanisms they have developed and evaluated). (Unfortunately, my lack of security clearance kept me out of the SCIF used for the talks on quantum computing and more sensitive topics).
<p class="text-right"><a href="/jason-spring-meeting-adversarial-machine-learning/">Read More…</a></p>
	

    
    <h2><a href="/can-machine-learning-ever-be-trustworthy/">Can Machine Learning Ever Be Trustworthy?</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-12-07 00:00:00 &#43;0000 UTC" itemprop="datePublished">7 December 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/talks">talks</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/university-of-maryland">University of Maryland</a>
    
  </span>
  
  
</div>


I gave the Booz Allen Hamilton Distinguished Colloquium at the University of Maryland on Can Machine Learning Ever Be Trustworthy?.
 [Video](https://vid.umd.edu/detsmediasite/Play/e8009558850944bfb2cac477f8d741711d?catalog=74740199-303c-49a2-9025-2dee0a195650) &middot; [SpeakerDeck](https://speakerdeck.com/evansuva/can-machine-learning-ever-be-trustworthy) 
 Abstract Machine learning has produced extraordinary results over the past few years, and machine learning systems are rapidly being deployed for critical tasks, even in adversarial environments. This talk will survey some of the reasons building trustworthy machine learning systems is inherently impossible, and dive into some recent research on adversarial examples.
<p class="text-right"><a href="/can-machine-learning-ever-be-trustworthy/">Read More…</a></p>
	

    
    <div class="row">
  <div class="column small-12">
    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li class="arrow" aria-disabled="true"><a href="/categories/talks/page/2/">&laquo; <em>Older<span class="show-for-sr"> blog entries</span></em></a></li>
      
      <li><span>Page 1 of 2</span></li>      
      
    </ul>    
    All Posts by <a href="//uvasrg.github.io/categories">Category</a> or <a href="//uvasrg.github.io/tags">Tags</a>.

  </div>
</div>

  </div>
</div>
</div>

    </main>
    
    
    <footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-6 medium-3">
      <img src="/images/uva_primary_rgb.png">
      </div>
    <div class="column small-6 medium-3">
      <a href="/"><b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
      <a href="mailto:evans@virginia.edu"><em>evans@virginia.edu</em></a>
    </div>
    <div classs="column small-4 medium-2"></div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>

    
    
    <div class="endofpage">
    </div>

    <script src="/js/jquery.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
