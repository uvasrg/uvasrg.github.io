<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>Posts | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      
        <p class="groupstyle">Security and Privacy Research</br>at the University of Virginia</p>
	      
	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      

<div class="container">
<div class="content">
<div class="row">
    
    
    <h2><a href="/voting-security/">Voting Security</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-10-31 00:00:00 &#43;0000 UTC" itemprop="datePublished">31 October 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/voting">voting</a>
    
  </span>
  
  
</div>


<p>I was interviewed for a local news story by Daniel Grimes on election
security: <a href="https://www.nbc29.com/2020/10/21/virginia-is-one-safer-states-cast-ballot-says-uva-cybersecurity-expert/"><em>UVA cybersecurity expert: Virginia is one of the safer states to cast a ballot</em></a>, NBC 29 News, 21 October 2020.</p>

	

    
    <h2><a href="/merlin-morgan-and-the-importance-of-thresholds-and-priors/">Merlin, Morgan, and the Importance of Thresholds and Priors</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-10-02 00:00:00 &#43;0000 UTC" itemprop="datePublished">2 October 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/bargav-jayaraman">Bargav Jayaraman</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/lingxiao-wang">Lingxiao Wang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/katherine-knipmeyer">Katherine Knipmeyer</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/quanquan-gu">Quanquan Gu</a>
    
  </span>
  
  
</div>


<p><em>Post by Katherine Knipmeyer</em></p>
<p>Machine learning poses a substantial risk that adversaries will be
able to discover information that the model does not intend to
reveal. One set of methods by which consumers can learn this sensitive
information, known broadly as <em>membership inference</em> attacks,
predicts whether or not a query record belongs to the training set. A
basic membership inference attack involves an attacker with a given
record and black-box access to a model who tries to determine whether
said record was a member of the model’s training set.</p>
<p class="text-right"><a href="/merlin-morgan-and-the-importance-of-thresholds-and-priors/">Read More…</a></p>
	

    
    <h2><a href="/robustrepresentations/">Adversarially Robust Representations</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-08-14 00:00:00 &#43;0000 UTC" itemprop="datePublished">14 August 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/icml">ICML</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/sicheng-zhu">Sicheng Zhu</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/xiao-zhang">Xiao Zhang</a>
    
  </span>
  
  
</div>


<p><em>Post by Sicheng Zhu</em></p>
<p>With the rapid development of deep learning and the explosive growth
of unlabeled data, <a href="https://arxiv.org/abs/1206.5538">representation
learning</a> is becoming increasingly
important. It has made impressive applications such as pre-trained
language models (e.g., <a href="https://arxiv.org/abs/1810.04805">BERT</a> and
<a href="https://github.com/openai/gpt-3">GPT-3</a>).</p>
<p>Popular as it is, representation learning raises concerns about the
robustness of learned representations under adversarial settings. For
example, <em>how can we compare the robustness to different
representations</em>, and <em>how can we build representations that enable
robust downstream classifiers</em>?</p>
<p class="text-right"><a href="/robustrepresentations/">Read More…</a></p>
	

    
    <h2><a href="/intrinsic-robustness-using-conditional-gans/">Intrinsic Robustness using Conditional GANs</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-08-14 00:00:00 &#43;0000 UTC" itemprop="datePublished">14 August 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/aistats">AISTATS</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/xiao-zhang">Xiao Zhang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jinghui-chen">Jinghui Chen</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/quanquan-gu">Quanquan Gu</a>
    
  </span>
  
  
</div>


<p>The video of Xiao&rsquo;s presentation for AISTATS 2020 is now available:
<a href="https://slideslive.com/38930305/understanding-the-intrinsic-robustness-of-image-distributions-using-conditional-generative-models"><em>Understanding the Intrinsic Robustness of Image Distributions using Conditional Generative Models</em></a></p>
<p>Starting with Gilmer et al. (2018), several works have demonstrated
the inevitability of adversarial examples based on different
assumptions about the underlying input probability space. It remains
unclear, however, whether these results apply to natural image
distributions. In this work, we assume the underlying data
distribution is captured by some conditional generative model, and
prove intrinsic robustness bounds for a general class of classifiers,
which solves an open problem in Fawzi et al. (2018). Building upon the
state-of-the-art conditional generative models, we study the intrinsic
robustness of two common image benchmarks under <em>l</em><sub>2</sub>
perturbations, and show the existence of a large gap between the
robustness limits implied by our theory and the adversarial robustness
achieved by current state-of-the-art robust models.</p>
<p class="text-right"><a href="/intrinsic-robustness-using-conditional-gans/">Read More…</a></p>
	

    
    <h2><a href="/hybrid-batch-attacks-at-usenix-security-2020/">Hybrid Batch Attacks at USENIX Security 2020</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-08-13 00:00:00 &#43;0000 UTC" itemprop="datePublished">13 August 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jianfeng-chi">Jianfeng Chi</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/usenix-security">USENIX Security</a>
    
  </span>
  
  
</div>


<p>Here&rsquo;s the video for Suya&rsquo;s presentation on <a href="/usenix-security-2020-hybrid-batch-attacks">Hybrid Batch Attacks</a> at USENIX Security 2020:</p>
<center>
  <video width="90%" id="usenix-media-video-1" data-setup="{}" poster="" class="video-js vjs-default-skin vjs-big-play-centered" preload="auto" controls>
    <source src='https://2459d6dc103cb5933875-c0245c5c937c5dedcca3f1764ecc9b2f.ssl.cf2.rackcdn.com/sec20/videos/0813/s5_machine_learning_1/3_sec20summer-paper412-presentation-video.mp4' type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'>
  </video><br> 
<a href="https://2459d6dc103cb5933875-c0245c5c937c5dedcca3f1764ecc9b2f.ssl.cf2.rackcdn.com/sec20/videos/0813/s5_machine_learning_1/3_sec20summer-paper412-presentation-video.mp4">Download Video [mp4]</a></p>
</center>
<p><a href="/usenix-security-2020-hybrid-batch-attacks">Blog Post</a><br>
Paper: [<a href="/docs/hybrid_attack.pdf">PDF</a>] [<a href="https://arxiv.org/abs/1908.07000">arXiv</a>]</p>

	

    
    <h2><a href="/pointwise-paraphrase-appraisal-is-potentially-problematic/">Pointwise Paraphrase Appraisal is Potentially Problematic</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-07-07 00:00:00 &#43;0000 UTC" itemprop="datePublished">7 July 2020</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/natural-language-processing">natural language processing</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/hannah-chen">Hannah Chen</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yangfeng-ji">Yangfeng Ji</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/acl">ACL</a>
    
  </span>
  
  
</div>


<p>Hannah Chen presented her paper on <em>Pointwise Paraphrase Appraisal is
Potentially Problematic</em> at the <a href="https://sites.google.com/view/acl20studentresearchworkshop/">ACL 2020 Student Research
Workshop</a>:</p>
<blockquote>
<p>The prevailing approach for training and evaluating paraphrase
identification models is constructed as a binary classification
problem: the model is given a pair of sentences, and is judged by how
accurately it classifies pairs as either paraphrases or
non-paraphrases. This pointwise-based evaluation method does not match
well the objective of most real world applications, so the goal of our
work is to understand how models which perform well under pointwise
evaluation may fail in practice and find better methods for evaluating
paraphrase identification models. As a first step towards that goal,
we show that although the standard way of fine-tuning BERT for
paraphrase identification by pairing two sentences as one sequence
results in a model with state-of-the-art performance, that model may
perform poorly on simple tasks like identifying pairs with two
identical sentences. Moreover, we show that these models may even
predict a pair of randomly-selected sentences with higher paraphrase
score than a pair of identical ones.</p>
<p class="text-right"><a href="/pointwise-paraphrase-appraisal-is-potentially-problematic/">Read More…</a></p>
	

    
    <h2><a href="/de-naming-the-blog/">De-Naming the Blog</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-06-21 00:00:00 &#43;0000 UTC" itemprop="datePublished">21 June 2020</time>
  </span>
  
</div>


<p>This blog was started in <a href="/2008/facebook-privacy.html">January 2008</a>, a bit over
eight years after I started as a professor at UVA and initiated the
research group. It was named after Thomas Jefferson&rsquo;s cipher wheel,
which <a href="http://www.cs.virginia.edu/~evans/cs588-fall2001/challenges/wheel-solved.html">has long
been</a>
(and <a href="https://github.com/evansuva/cipherschool">remains</a>) one of my
<a href="https://www.cs.virginia.edu/~evans/crypto/day1-jefferson.html">favorite ways to introduce
cryptography</a>.</p>
<p>
<center><img src="/images/jwlogo-small.jpg" width="60%"></center>
</p>
<p>Figuring out how to honor our history, including Jefferson&rsquo;s <a href="https://youtu.be/cJbIXG50RCE?t=388">founding
of the University</a>, and appreciate his
<a href="https://www.monticello.org/site/research-and-collections/virginia-statute-religious-freedom">ideals</a>
and <a href="https://www.cs.virginia.edu/~evans/cs655/readings/declaration.html">enormous
contributions</a>,
while confronting the reality of Jefferson as a slave owner and
abuser, will be a challenge and responsibility for people above my
administrative rank. But, I&rsquo;ve come to see that it is harmful to have
a blogged named after Jefferson so have removed the Jefferson&rsquo;s Wheel
name from this research group blog.</p>
<p class="text-right"><a href="/de-naming-the-blog/">Read More…</a></p>
	

    
    <h2><a href="/oakland-test-of-time-awards/">Oakland Test-of-Time Awards</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2020-05-23 00:00:00 &#43;0000 UTC" itemprop="datePublished">23 May 2020</time>
  </span>
  
</div>


<p>I chaired the committee to select Test-of-Time Awards for the IEEE Symposium on Security and Privacy symposia from 1995-2006, which were presented at the Opening Section of the <a href="https://www.ieee-security.org/TC/SP2020/awards.html">41<sup>st</sup> <em>IEEE Symposium on Security and Privacy</em></a>.</p>
<center>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/EwT1tnyin1M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

	

    
    <h2><a href="/neurips2019/">NeurIPS 2019</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-12-16 00:00:00 &#43;0000 UTC" itemprop="datePublished">16 December 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/xiao-zhang">Xiao Zhang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/neurips">NeurIPS</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/saeed-mahloujifar">Saeed Mahloujifar</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/mohammad-mahmoody">Mohammad Mahmoody</a>
    
  </span>
  
  
</div>


<p>
Here's a video of Xiao Zhang's presentation at NeurIPS 2019: <br>
<a href="https://slideslive.com/38921718/track-2-session-1"><em>https://slideslive.com/38921718/track-2-session-1</em></a> (starting at 26:50)
</p>
<p>
See <A href="/neurips-2019-empirically-measuring-concentration/">this post</a> for info on the paper.
</p>
Here are a few pictures from NeurIPS 2019 (by Sicheng Zhu and Mohammad Mahmoody):
<p>
<center>
<a href="/images/NeurIPS2019/IMG_6759.JPG"><img src="/images/NeurIPS2019/IMG_6759.JPG" width="75%"></a><br>
<p><br></p>
<a href="/images/NeurIPS2019/IMG_6777.JPG"><img src="/images/NeurIPS2019/IMG_6777.JPG" width="75%"></a><br>
<p><br></p>
<a href="/images/NeurIPS2019/xiao-poster.jpg"><img src="/images/NeurIPS2019/xiao-poster.jpg"></a><br>
</center>
</p>

	

    
    <h2><a href="/usenix-security-2020-hybrid-batch-attacks/">USENIX Security 2020: Hybrid Batch Attacks</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-12-14 00:00:00 &#43;0000 UTC" itemprop="datePublished">14 December 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jianfeng-chi">Jianfeng Chi</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/usenix-security">USENIX Security</a>
    
  </span>
  
  
</div>


<p><b><font color="red">New:</font> <a href="/hybrid-batch-attacks-at-usenix-security-2020/">Video Presentation</a></b></p>
<h2 id="finding-black-box-adversarial-examples-with-limited-queries">Finding Black-box Adversarial Examples with Limited Queries</h2>
<p>Black-box attacks generate adversarial examples (AEs) against deep
neural networks with only API access to the victim model.</p>
<p>Existing black-box attacks can be grouped into two main categories:</p>
<ul>
<li>
<p><strong>Transfer Attacks</strong> use white-box attacks on local models to find
candidate adversarial examples that transfer to the target model.</p>
</li>
<li>
<p><strong>Optimization Attacks</strong> use queries to the target model and apply
optimization techniques to search for adversarial examples.</p>
<p class="text-right"><a href="/usenix-security-2020-hybrid-batch-attacks/">Read More…</a></p>
	

    
    <div class="row">
  <div class="column small-12">
    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li class="arrow" aria-disabled="true"><a href="/post/page/7/">&laquo; <em>Older<span class="show-for-sr"> blog entries</span></em></a></li>
      
      <li><span>Page 6 of 10</span></li>      
      
      <li class="arrow" aria-disabled="true"><a href="/post/page/5/"><em>Newer<span class="show-for-sr"> blog entries</span></em>:&nbsp;&raquo;</a></li>
      
    </ul>    
    All Posts by <a href="//uvasrg.github.io/categories">Category</a> or <a href="//uvasrg.github.io/tags">Tags</a>.

  </div>
</div>

</div>
</div>
</div>

    </main>
    
    
    <footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>

    
    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
