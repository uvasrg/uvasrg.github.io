<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>Posts | Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      
        <p class="groupstyle">Security and Privacy Research</br>at the University of Virginia</p>
	      
	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      

<div class="container">
<div class="content">
<div class="row">
    
    
    <h2><a href="/usenix-security-2020-hybrid-batch-attacks/">USENIX Security 2020: Hybrid Batch Attacks</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-12-14 00:00:00 &#43;0000 UTC" itemprop="datePublished">14 December 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jianfeng-chi">Jianfeng Chi</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/usenix-security">USENIX Security</a>
    
  </span>
  
  
</div>


<p><b><font color="red">New:</font> <a href="/hybrid-batch-attacks-at-usenix-security-2020/">Video Presentation</a></b></p>
<h2 id="finding-black-box-adversarial-examples-with-limited-queries">Finding Black-box Adversarial Examples with Limited Queries</h2>
<p>Black-box attacks generate adversarial examples (AEs) against deep
neural networks with only API access to the victim model.</p>
<p>Existing black-box attacks can be grouped into two main categories:</p>
<ul>
<li>
<p><strong>Transfer Attacks</strong> use white-box attacks on local models to find
candidate adversarial examples that transfer to the target model.</p>
</li>
<li>
<p><strong>Optimization Attacks</strong> use queries to the target model and apply
optimization techniques to search for adversarial examples.</p>
<p class="text-right"><a href="/usenix-security-2020-hybrid-batch-attacks/">Read More…</a></p>
	

    
    <h2><a href="/neurips-2019-empirically-measuring-concentration/">NeurIPS 2019: Empirically Measuring Concentration</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-11-22 00:00:00 &#43;0000 UTC" itemprop="datePublished">22 November 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/xiao-zhang">Xiao Zhang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/neurips">NeurIPS</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/saeed-mahloujifar">Saeed Mahloujifar</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/mohammad-mahmoody">Mohammad Mahmoody</a>
    
  </span>
  
  
</div>


<p><a href="https://www.people.virginia.edu/~xz7bc/">Xiao Zhang</a> will
present our work (with <a
href="https://www.cs.virginia.edu/~sm5fd/">Saeed Mahloujifar</a> and
<a href="https://www.cs.virginia.edu/~mohammad/">Mohamood
Mahmoody</a>) as a spotlight at <a href="https://nips.cc/Conferences/2019/ScheduleMultitrack?event=15792">NeurIPS
2019</a>,
Vancouver, 10 December 2019.</p>
<p>Recent theoretical results, starting with Gilmer et al.&rsquo;s
<a href="https://aipavilion.github.io/"><em>Adversarial Spheres</em></a> (2018), show
that if inputs are drawn from a concentrated metric probability space,
then adversarial examples with small perturbation are inevitable.c The
key insight from this line of research is that <a href="https://en.wikipedia.org/wiki/Concentration_of_measure%22%3E"><em>concentration of
measure</em></a>
gives lower bound on adversarial risk for a large collection of
classifiers (e.g. imperfect classifiers with risk at least $\alpha$),
which further implies the impossibility results for robust learning
against adversarial examples.</p>
<p class="text-right"><a href="/neurips-2019-empirically-measuring-concentration/">Read More…</a></p>
	

    
    <h2><a href="/white-house-visit/">White House Visit</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-11-08 00:00:00 &#43;0000 UTC" itemprop="datePublished">8 November 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/conferences">conferences</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/multi-party-computation">multi-party computation</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/white-house">White House</a>
    
  </span>
  
  
</div>


<p>I had a chance to visit the White House for a Roundtable on
<em>Accelerating Responsible Sharing of Federal Data</em>. The meeting was
held under &ldquo;Chatham House Rules&rdquo;, so I won&rsquo;t mention the other
participants here.</p>
<div style="padding-bottom: 2em">
<center>
<a href="/images/whitehouse/IMG_20191030_080936.png"><img src="/images/whitehouse/IMG_20191030_080936.png" width=75%>
</center>
</div>
<p>The meeting was held in the <a href="https://en.wikipedia.org/wiki/Roosevelt_Room">Roosevelt
Room</a> of the White
House. We entered through the visitor&rsquo;s side entrance. After a
security gate (where you put your phone in a lockbox, so no pictures
inside) with a TV blaring Fox News, there is a pleasant lobby for
waiting, and then an entrance right into the Roosevelt Room. (We
didn&rsquo;t get to see the entrance in the opposite corner of the room,
which is just a hallway across from the Oval Office.)</p>
<p class="text-right"><a href="/white-house-visit/">Read More…</a></p>
	

    
    <h2><a href="/jobs-for-humans-2029-2059/">Jobs for Humans, 2029-2059</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-10-30 00:00:00 &#43;0000 UTC" itemprop="datePublished">30 October 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/artificial-intelligence">artificial intelligence</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/outreach">outreach</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/education">education</a>
    
  </span>
  
  
</div>


<p>I was honored to particilate in a panel at an event on
<a href="https://aohdc.org/adulteducationandai/"><em>Adult Education in the Age of Artificial Intelligence</em></a> that was run by <a href="https://www.thegreatcoursesplus.com/">The Great Courses</a> as a fundraiser for the <a href="https://aohdc.org/">Academy of Hope</a>, an adult public charter school in Washington, D.C.</p>
<p>I spoke first, following a few introductory talks, and was followed by
Nicole Smith and Ellen Scully-Russ, and a keynote from Dexter Manley,
Super Bowl winner with the Washington Redskins. After a short break,
Kavitha Cardoza moderated a very interesting panel discussion. A
recording of the talk and rest of the event is supposed to be
available to Great Courses Plus subscribers.</p>
<p class="text-right"><a href="/jobs-for-humans-2029-2059/">Read More…</a></p>
	

    
    <h2><a href="/research-symposium-posters/">Research Symposium Posters</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-10-08 00:00:00 &#43;0000 UTC" itemprop="datePublished">8 October 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/research">research</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/mainuddin-jonas">Mainuddin Jonas</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/xiao-zhang">Xiao Zhang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/bargav-jayaraman">Bargav Jayaraman</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/hannah-chen">Hannah Chen</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/anshuman-suri">Anshuman Suri</a>
    
  </span>
  
  
</div>


<p>Five students from our group presented posters at the department&rsquo;s
<a href="https://engineering.virginia.edu/cs-research-symposium-fall-2019">Fall Research
Symposium</a>:</p>
<center>
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQcaahIxPyCHIMJti6tRB9HM_RreRhZkGH4wCN7YjTwiHSqcHod9v3hDFj-ZS1TtXp9OtBEBCV8OPH4/embed?start=false&loop=false&delayms=3000" frameborder="0" width="764" height="453" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe><br>
Anshuman Suri's Overview Talk
</center>
<center>
<embed src="/docs/symposters2019/evaluatingdpml-poster.pdf" width="95%" height="300" type="application/pdf"> <br>
Bargav Jayaraman, <em>Evaluating Differentially Private Machine Learning In Practice</em> 
[<a href="
<a href="/docs/symposters2019/evaluatingdpml-poster.pdf">Poster</a>]<br>
[<a href="https://www.cs.virginia.edu/~evans/pubs/usenix2019/">Paper</a> (USENIX Security 2019)]
</center>
<p><br></br></p>
<center>
<embed src="/docs/symposters2019/pretrainedvulnerable-poster.pdf" width="95%" height="300" type="application/pdf"><br>
Hannah Chen [<a href="/docs/symposters2019/pretrainedvulnerable-poster.pdf">Poster</a>]
</center>
<p><br></br></p>
<center>
<embed src="/docs/symposters2019/measuringconcentration-poster.pdf" width="95%" height="300" type="application/pdf"><br>
Xiao Zhang [<a href="/docs/symposters2019/measuringconcentration-poster.pdf">Poster<a>]<br>
[<a href="https://arxiv.org/abs/1905.12202">Paper</a> (NeurIPS 2019)]
</center>
<p><br></br></p>
<center>
<embed src="/docs/symposters2019/diversemodels-poster.pdf" width="95%" height="300" type="application/pdf"><br>
Mainudding Jonas [<a href="/docs/symposters2019/diversemodels-poster.pdf">Poster</a>]
</center>
<p><br></br></p>
<center>
<embed src="/docs/symposters2019/hybridbatch-poster.pdf" width="95%" height="300" type="application/pdf"><br>
Fnu Suya [<a href="/docs/symposters2019/hybridbatch-poster.pdf">Poster<a>]<br>
[<a href="https://arxiv.org/abs/1908.07000">Paper</a> (USENIX Security 2020)]
</center>

	

    
    <h2><a href="/cantors-no-longer-lost-proof/">Cantor&#39;s (No Longer) Lost Proof</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-09-26 00:00:00 &#43;0000 UTC" itemprop="datePublished">26 September 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/uncountability">uncountability</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/teaching">teaching</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/history">history</a>
    
  </span>
  
  
</div>


<p>In preparing to cover Cantor&rsquo;s proof of different infinite set
cardinalities (one of my all-time favorite topics!) in our <a href="https://uvatoc.github.io/class4/">theory of
computation course</a>, I found various
conflicting accounts of what Cantor originally proved. So, I figured
it would be easy to search the web to find the original proof.</p>
<p>Shockingly, at least as far as I could find<sup>1</sup>, it didn&rsquo;t
exist on the web! The closest I could find was in Google Books the
1892 volume of the <em>Jähresbericht Deutsche
Mathematiker-Vereinigung</em> (which many of the references pointed
to), but in fact not the first value of that journal which contains
the actual proof.</p>
<p class="text-right"><a href="/cantors-no-longer-lost-proof/">Read More…</a></p>
	

    
    <h2><a href="/fosad2019/">FOSAD Trustworthy Machine Learning Mini-Course</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-28 00:00:00 &#43;0000 UTC" itemprop="datePublished">28 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>
    
  </span>
  
  
</div>


<p>I taught a mini-course on <em>Trustworthy Machine Learning</em> at the <a href="http://www.sti.uniurb.it/events/fosad19/"><em>19th
International School on Foundations of Security Analysis and
Design</em></a> in Bertinoro, Italy.</p>
<center><a href="/images/bertinoro-big.jpg"><img src="/images/bertinoro.jpg" width="90%"></a></center>
<p>Slides from my three (two-hour) lectures are posted below, along with
some links to relevant papers and resources.</p>
<h2 id="class-1-introductionattacks">Class 1: Introduction/Attacks</h2>
<center>
<script async class="speakerdeck-embed" data-id="0ad1775bcc244876ac4df1880a864e78" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
</center>
<p>The PDF malware evasion attack is described in this paper:</p>
<blockquote>
Weilin Xu, Yanjun Qi, and David Evans. 
<em><a href="https://www.cs.virginia.edu/evans/pubs/ndss2016/">Automatically Evading Classifiers: A Case Study on PDF Malware Classifiers</a></em>.
<a href="https://www.internetsociety.org/events/ndss-symposium-2016"><em>Network and Distributed System Security Symposium</em></a> (NDSS). San Diego, CA. 21-24 February 2016. [<a href="https://www.cs.virginia.edu/evans/pubs/ndss2016/evademl.pdf">PDF</a>] [<a href="https://evademl.org/gpevasion/">EvadeML.org</a>]
</blockquote>
<h2 id="class-2-defenses">Class 2: Defenses</h2>
<center>
<script async class="speakerdeck-embed" data-id="cf560cce9e4b418397d2df3429ddc8f9" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
</center>
<p>This paper describes the feature squeezing framework:</p>
<p class="text-right"><a href="/fosad2019/">Read More…</a></p>
	

    
    <h2><a href="/evaluating-differentially-private-machine-learning-in-practice/">Evaluating Differentially Private Machine Learning in Practice</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-27 00:00:00 &#43;0000 UTC" itemprop="datePublished">27 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/bargav-jayaraman">Bargav Jayaraman</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/differential-privacy">differential privacy</a>
    
  </span>
  
  
</div>


<p>(Cross-post by <a href="https://bargavjayaraman.github.io/post/evaluating-dpml-results/">Bargav Jayaraman</a>)</p>
<p>With the recent advances in composition of differential private
mechanisms, the research community has been able to achieve meaningful
deep learning with privacy budgets in single digits. Rènyi
differential privacy (RDP) is one mechanism that provides tighter
composition which is widely used because of its implementation in
TensorFlow Privacy (recently, Gaussian differential privacy (GDP) has
shown a tighter analysis for low privacy budgets, but it was not yet
available when we did this work). But the central question that
remains to be answered is: <em>how private are these methods in
practice?</em></p>
<p class="text-right"><a href="/evaluating-differentially-private-machine-learning-in-practice/">Read More…</a></p>
	

    
    <h2><a href="/usenix-security-symposium-2019/">USENIX Security Symposium 2019</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-26 00:00:00 &#43;0000 UTC" itemprop="datePublished">26 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/bargav-jayaraman">Bargav Jayaraman</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/sam-havron">Sam Havron</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/serge-egelman">Serge Egelman</a>
    
  </span>
  
  
</div>


<p>Bargav Jayaraman presented our paper on <a href="https://arxiv.org/abs/1902.08874"><em>Evaluating Differentially Private Machine Learning in Practice</em></a> at the <a
href="https://www.usenix.org/conference/usenixsecurity19">28<sup>th</sup>
USENIX Security Symposium</em></a> in Santa Clara, California.</p>
<center>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/JAGhqbY_U50" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>
<center>
<script async class="speakerdeck-embed" data-id="dfdd40e4ba2b46e1baee68219df82de7" data-ratio="1.29456384323641" src="//speakerdeck.com/assets/embed.js"></script>
</center>
<center><img src="/images/usenix2019/bargav.jpg" width=80%"></center>
<p>Summary by Lea Kissner:</p>
<center>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Hey it&#39;s the results! <a href="https://t.co/ru1FbkESho">pic.twitter.com/ru1FbkESho</a></p>&mdash; Lea Kissner (@LeaKissner) <a href="https://twitter.com/LeaKissner/status/1162518239177371648?ref_src=twsrc%5Etfw">August 17, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p>Also, great to see several UVA folks at the conference including:</p>
<ul>
<li><a href="https://havron.dev">Sam Havron</a> (BSCS 2017, now a PhD student at
Cornell) presented a paper on the work he and his colleagues have
done on <a href="https://havron.dev/pubs/clinicalsec.pdf">computer security for victims of intimate partner violence</a>.</li>
</ul>
<center><img src="/images/usenix2019/havron.jpg" width=80%"></center>
<ul>
<li>
<p><a href="https://www.guanotronic.com/~serge/">Serge Egelman</a> (BSCS 2004) was an author on the paper <a href="https://www.usenix.org/conference/usenixsecurity19/presentation/reardon"><em>50 Ways to Leak Your Data: An
Exploration of Apps&rsquo; Circumvention of the Android Permissions
System</em></a>
(which was recognized by a Distinguished Paper Award). His paper in
SOUPS on <a href="https://www.usenix.org/system/files/soups2019-frik.pdf"><em>Privacy and Security Threat Models and Mitigation
Strategies of Older
Adults</em></a> was highlighted in Alex Stamos&rsquo; excellent talk.</p>
<p class="text-right"><a href="/usenix-security-symposium-2019/">Read More…</a></p>
	

    
    <h2><a href="/google-security-and-privacy-workshop/">Google Security and Privacy Workshop</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-25 00:00:00 &#43;0000 UTC" itemprop="datePublished">25 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/google">Google</a>
    
  </span>
  
  
</div>


<p>I presented a short talk at a workshop at Google on <em>Adversarial ML: Closing Gaps between Theory and Practice</em> (mostly fun for the <a href="https://www.youtube.com/watch?v=TVmjjfTvnFs">movie of me trying to solve Google&rsquo;s CAPTCHA</a> on the last slide):</p>
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTKeMueFNQPz0Pms4EGKoYOXVEg92IBi55babPKG5WRrhHRR2PmIYwZIyLsZ11ucKSahqjjp3Zxd5i3/embed?start=true&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
<p>Getting the actual screencast to fit into the limited time for this talk challenged the limits of my video editing skills.</p>
<center>
<img src="/images/googledonuts.jpg" width="90%"><br>
I can say with some confidence, Google does donuts much better than they <a href="https://freedom-to-tinker.com/2019/08/23/deconstructing-googles-excuses-on-tracking-protection/">do cookies</a>!
</center>

	

    
    <div class="row">
  <div class="column small-12">
    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li class="arrow" aria-disabled="true"><a href="/post/page/8/">&laquo; <em>Older<span class="show-for-sr"> blog entries</span></em></a></li>
      
      <li><span>Page 7 of 10</span></li>      
      
      <li class="arrow" aria-disabled="true"><a href="/post/page/6/"><em>Newer<span class="show-for-sr"> blog entries</span></em>:&nbsp;&raquo;</a></li>
      
    </ul>    
    All Posts by <a href="//uvasrg.github.io/categories">Category</a> or <a href="//uvasrg.github.io/tags">Tags</a>.

  </div>
</div>

</div>
</div>
</div>

    </main>
    
    
    <footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>

    
    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
